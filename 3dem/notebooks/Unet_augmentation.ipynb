{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82fc12ee",
   "metadata": {},
   "source": [
    "#### augmentation for the Unet structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3124edd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading \n",
    "\n",
    "import os\n",
    "import mrcfile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "from tqdm import tqdm  # ! this might result into problem with 'object'\n",
    "import os\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19d4cd1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]E:\\INSTALL\\anaconda\\envs\\seg\\lib\\site-packages\\mrcfile\\mrcinterpreter.py:219: RuntimeWarning: Unrecognised machine stamp: 0x00 0x00 0x00 0x00\n",
      "  warnings.warn(str(err), RuntimeWarning)\n",
      " 50%|██████████████████████████████████████████                                          | 1/2 [00:00<00:00,  7.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tomo1_focalseries.mrc\n",
      "tomo2_focalseries.mrc\n",
      "tomo3_focalseries.mrc\n",
      "tomo1_groundtruth.mrc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tomo2_groundtruth.mrc\n",
      "tomo3_groundtruth.mrc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def readMRC(path):\n",
    "    with mrcfile.open(path, mode='r+', permissive=True) as mrc:\n",
    "        mrc.header.map = mrcfile.constants.MAP_ID # for synthetic data, need to generate ID\n",
    "        data = mrc.data\n",
    "    return data\n",
    "\n",
    "DATA_PATH = 'F:/MDC/4.1dataAugNeat/EM/3dem/data/interim/synthetic/'\n",
    "data_ids = next(os.walk(DATA_PATH))[1]\n",
    "raw = []\n",
    "for n, id_ in tqdm(enumerate(data_ids), total=len(data_ids)):  \n",
    "    path = DATA_PATH + id_\n",
    "    datanames = os.listdir(path)\n",
    "    for dataname in datanames:\n",
    "        if os.path.splitext(dataname)[1] == '.mrc': # all .mrc under the path\n",
    "            temp = readMRC(path + \"/\" + dataname).astype(np.uint8)\n",
    "            raw.append(temp)\n",
    "            print(dataname)\n",
    "            \n",
    "focal = raw[0:3]\n",
    "GT = raw[3:len(raw)]\n",
    "del raw, temp, datanames, dataname, path, data_ids, n, id_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c8a5117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 256, 256)\n",
      "(512, 256, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\INSTALL\\anaconda\\envs\\seg\\lib\\site-packages\\ipykernel_launcher.py:17: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    }
   ],
   "source": [
    "# raw data sorting: padding, reshape\n",
    "\n",
    "import torchio as tio\n",
    "from patchify import patchify, unpatchify\n",
    "\n",
    "# training dataset raw\n",
    "train_raw = np.vstack(([focal[0], focal[1]]));train = train_raw[...,np.newaxis].transpose((3,1,2,0)); label = np.vstack(([GT[0], GT[1]]))#;label = train_label[...,np.newaxis]\n",
    "\n",
    "trainIO = tio.ScalarImage(tensor=train)\n",
    "target_shape = 256,256,512  # padding into the same size\n",
    "crop_pad = tio.CropOrPad(target_shape, padding_mode='mean'); resized = crop_pad(trainIO) # padding with mean\n",
    "train_padd = resized.numpy().transpose((3,1,2,0)); train_padd = train_padd[...,0]\n",
    "print(train_padd.shape);print(label.shape)\n",
    "\n",
    "# testing dataset raw\n",
    "X_test = focal[2]; X_test = X_test[...,np.newaxis].transpose((3,1,2,0))\n",
    "Y_test_label = GT[2]; Y_test_label = (Y_test_label > 0.5).astype(np.float) \n",
    "\n",
    "testIO = tio.ScalarImage(tensor=X_test)\n",
    "target_shape = 256,256,256\n",
    "crop_pad = tio.CropOrPad(target_shape, padding_mode='mean'); resized = crop_pad(testIO)\n",
    "test_padd = resized.numpy().transpose((3,1,2,0)); test_padd = test_padd[...,0];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1b4ae62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# patchify the images\n",
    "\n",
    "def rawPatch(imageStack,patchPara):\n",
    "    all_img_patches = []\n",
    "\n",
    "    for img in range(imageStack.shape[0]):\n",
    "        large_image = imageStack[img]\n",
    "\n",
    "        patches_img = patchify(large_image, (patchPara['x'],patchPara['y']), step=patchPara['step'])  # no overlap\n",
    "\n",
    "        for i in range(patches_img.shape[0]):\n",
    "            for j in range(patches_img.shape[1]):\n",
    "\n",
    "                single_patch_img = patches_img[i,j,:,:]\n",
    "                single_patch_img = (single_patch_img.astype('float32')) / 255.  # remember to standarize into 0-1\n",
    "\n",
    "                all_img_patches.append(single_patch_img)\n",
    "    \n",
    "    return all_img_patches, patches_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17ba52a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\INSTALL\\anaconda\\envs\\seg\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256, 256, 3)\n",
      "(256, 256, 256, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\INSTALL\\anaconda\\envs\\seg\\lib\\site-packages\\ipykernel_launcher.py:12: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "# train dataset\n",
    "patchPara = {'x': 256, 'y': 256, 'step':256}\n",
    "Xtrain_patches, _ = rawPatch(train_padd, patchPara);Xtrain_patches = np.stack((Xtrain_patches,)*3, axis=-1) # dock 3 times, the model expects 3 channel\n",
    "# print(Xtrain_patches.shape)\n",
    "\n",
    "Ytrain_patches, _ = rawPatch(label, patchPara);Ytrain_patches = np.expand_dims(Ytrain_patches, -1)\n",
    "Ytrain_patches = (Ytrain_patches > 0.5).astype(np.float) # binarize the data\n",
    "\n",
    "# test dataset\n",
    "Xtest_patches, patchSize = rawPatch(test_padd, patchPara);Xtest_patches = np.stack((Xtest_patches,)*3, axis=-1)\n",
    "Ytest_patches, _ = rawPatch(Y_test_label, patchPara);Ytest_patches = np.expand_dims(Ytest_patches, -1)\n",
    "Ytest_patches = (Ytest_patches > 0.5).astype(np.float)\n",
    "print(Xtest_patches.shape);print(Ytest_patches.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "358d2156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unet structure in blocks\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\n",
    "from tensorflow.keras.optimizers import Adam  # ! notice here must write in tensorflow.keras\n",
    "from keras.layers import Activation, MaxPool2D, Concatenate\n",
    "\n",
    "\n",
    "def conv_block(input, num_filters):\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(input)\n",
    "    x = BatchNormalization()(x)   #Not in the original network. \n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)  #Not in the original network\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "#Encoder block: Conv block followed by maxpooling\n",
    "\n",
    "def encoder_block(input, num_filters):\n",
    "    x = conv_block(input, num_filters)\n",
    "    p = MaxPool2D((2, 2))(x)\n",
    "    return x, p   \n",
    "\n",
    "#Decoder block\n",
    "#skip features gets input from encoder for concatenation\n",
    "\n",
    "def decoder_block(input, skip_features, num_filters):\n",
    "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n",
    "    x = Concatenate()([x, skip_features])\n",
    "    x = conv_block(x, num_filters)\n",
    "    return x\n",
    "\n",
    "#Build Unet using the blocks\n",
    "def build_unet(input_shape):\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    s1, p1 = encoder_block(inputs, 64)\n",
    "    s2, p2 = encoder_block(p1, 128)\n",
    "    s3, p3 = encoder_block(p2, 256)\n",
    "    s4, p4 = encoder_block(p3, 512)\n",
    "\n",
    "    b1 = conv_block(p4, 1024) #Bridge\n",
    "\n",
    "    d1 = decoder_block(b1, s4, 512)\n",
    "    d2 = decoder_block(d1, s3, 256)\n",
    "    d3 = decoder_block(d2, s2, 128)\n",
    "    d4 = decoder_block(d3, s1, 64)\n",
    "\n",
    "    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)  #Binary (can be multiclass)\n",
    "\n",
    "    model = Model(inputs, outputs, name=\"U-Net\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "572a1d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"U-Net\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 256, 256, 64  1792        ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 256, 256, 64  256        ['conv2d[0][0]']                 \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 256, 256, 64  0           ['batch_normalization[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 256, 256, 64  36928       ['activation[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 256, 256, 64  256        ['conv2d_1[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 256, 256, 64  0           ['batch_normalization_1[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 128, 128, 64  0           ['activation_1[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 128, 128, 12  73856       ['max_pooling2d[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 128, 128, 12  512        ['conv2d_2[0][0]']               \n",
      " rmalization)                   8)                                                                \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 128, 128, 12  0           ['batch_normalization_2[0][0]']  \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 128, 128, 12  147584      ['activation_2[0][0]']           \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 128, 128, 12  512        ['conv2d_3[0][0]']               \n",
      " rmalization)                   8)                                                                \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 128, 128, 12  0           ['batch_normalization_3[0][0]']  \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 128)  0          ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 64, 64, 256)  295168      ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 64, 64, 256)  1024       ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 64, 64, 256)  0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 64, 64, 256)  590080      ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 64, 64, 256)  1024       ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 64, 64, 256)  0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 256)  0          ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 32, 32, 512)  1180160     ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 32, 32, 512)  2048       ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 32, 32, 512)  0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 32, 32, 512)  2359808     ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 32, 32, 512)  2048       ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 32, 32, 512)  0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 512)  0          ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 16, 16, 1024  4719616     ['max_pooling2d_3[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 16, 16, 1024  4096       ['conv2d_8[0][0]']               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 16, 16, 1024  0           ['batch_normalization_8[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 16, 16, 1024  9438208     ['activation_8[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 16, 16, 1024  4096       ['conv2d_9[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 16, 16, 1024  0           ['batch_normalization_9[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTransp  (None, 32, 32, 512)  2097664    ['activation_9[0][0]']           \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 32, 32, 1024  0           ['conv2d_transpose[0][0]',       \n",
      "                                )                                 'activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 32, 32, 512)  4719104     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 32, 32, 512)  2048       ['conv2d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 32, 32, 512)  0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 32, 32, 512)  2359808     ['activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 32, 32, 512)  2048       ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 32, 32, 512)  0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2DTran  (None, 64, 64, 256)  524544     ['activation_11[0][0]']          \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 64, 64, 512)  0           ['conv2d_transpose_1[0][0]',     \n",
      "                                                                  'activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 64, 64, 256)  1179904     ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 64, 64, 256)  1024       ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 64, 64, 256)  0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 64, 64, 256)  590080      ['activation_12[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 64, 64, 256)  1024       ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 64, 64, 256)  0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2DTran  (None, 128, 128, 12  131200     ['activation_13[0][0]']          \n",
      " spose)                         8)                                                                \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 128, 128, 25  0           ['conv2d_transpose_2[0][0]',     \n",
      "                                6)                                'activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 128, 128, 12  295040      ['concatenate_2[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 128, 128, 12  512        ['conv2d_14[0][0]']              \n",
      " ormalization)                  8)                                                                \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 128, 128, 12  0           ['batch_normalization_14[0][0]'] \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 128, 128, 12  147584      ['activation_14[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 128, 128, 12  512        ['conv2d_15[0][0]']              \n",
      " ormalization)                  8)                                                                \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 128, 128, 12  0           ['batch_normalization_15[0][0]'] \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_transpose_3 (Conv2DTran  (None, 256, 256, 64  32832      ['activation_15[0][0]']          \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 256, 256, 12  0           ['conv2d_transpose_3[0][0]',     \n",
      "                                8)                                'activation_1[0][0]']           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 256, 256, 64  73792       ['concatenate_3[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 256, 256, 64  256        ['conv2d_16[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 256, 256, 64  0           ['batch_normalization_16[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 256, 256, 64  36928       ['activation_16[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 256, 256, 64  256        ['conv2d_17[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 256, 256, 64  0           ['batch_normalization_17[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 256, 256, 1)  65          ['activation_17[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 31,055,297\n",
      "Trainable params: 31,043,521\n",
      "Non-trainable params: 11,776\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\INSTALL\\anaconda\\envs\\seg\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# compile the model\n",
    "\n",
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "input_shape = (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n",
    "\n",
    "model = build_unet(input_shape)\n",
    "model.compile(optimizer=Adam(lr = 1e-3), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9fe147b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data augmentation\n",
    "\n",
    "seed=24  # gurantee the images and masks are the same with augmentaion\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# dictionary for augmentation\n",
    "img_data_gen_args = dict(rotation_range=90,\n",
    "                     width_shift_range=0.3,\n",
    "                     height_shift_range=0.3,\n",
    "                     shear_range=0.5,\n",
    "                     zoom_range=0.3,\n",
    "                     horizontal_flip=True,\n",
    "                     vertical_flip=True,\n",
    "                     fill_mode='reflect')\n",
    "\n",
    "mask_data_gen_args = dict(rotation_range=90,\n",
    "                     width_shift_range=0.3,\n",
    "                     height_shift_range=0.3,\n",
    "                     shear_range=0.5,\n",
    "                     zoom_range=0.3,\n",
    "                     horizontal_flip=True,\n",
    "                     vertical_flip=True,\n",
    "                     fill_mode='reflect',\n",
    "                     preprocessing_function = lambda x: np.where(x>0, 1, 0).astype(x.dtype)) \n",
    "#Binarize the output again. Because the new-generated images comes with interperated values\n",
    "\n",
    "image_data_generator = ImageDataGenerator(**img_data_gen_args)\n",
    "\n",
    "\n",
    "batch_size= 8\n",
    "\n",
    "X_train = Xtrain_patches; Y_train = Ytrain_patches;\n",
    "X_test = Xtest_patches; Y_test = Ytest_patches;\n",
    "image_generator = image_data_generator.flow(X_train, seed=seed, batch_size=batch_size)\n",
    "valid_img_generator = image_data_generator.flow(X_test, seed=seed, batch_size=batch_size) #Default batch size 32, if not specified here\n",
    "\n",
    "mask_data_generator = ImageDataGenerator(**mask_data_gen_args)\n",
    "mask_generator = mask_data_generator.flow(Y_train, seed=seed, batch_size=batch_size)  # the seed is same\n",
    "valid_mask_generator = mask_data_generator.flow(Y_test, seed=seed, batch_size=batch_size)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e65d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 另外的处理数据的方式\n",
    "# image_data_generator = ImageDataGenerator(**img_data_gen_args)\n",
    "# image_data_generator.fit(X_train, augment=True, seed=seed)\n",
    "\n",
    "# image_generator = image_data_generator.flow(X_train, seed=seed)\n",
    "# valid_img_generator = image_data_generator.flow(X_test, seed=seed)\n",
    "\n",
    "# mask_data_generator = ImageDataGenerator(**mask_data_gen_args)\n",
    "# mask_data_generator.fit(y_train, augment=True, seed=seed)\n",
    "# mask_generator = mask_data_generator.flow(y_train, seed=seed)\n",
    "# valid_mask_generator = mask_data_generator.flow(y_test, seed=seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "790042b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_image_mask_generator(image_generator, mask_generator):\n",
    "    train_generator = zip(image_generator, mask_generator)\n",
    "    for (img, mask) in train_generator:\n",
    "        yield (img, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78606e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator\n",
    "\n",
    "my_generator = my_image_mask_generator(image_generator, mask_generator)  # give out the image generator and mask at teh same time\n",
    "\n",
    "validation_datagen = my_image_mask_generator(valid_img_generator, valid_mask_generator)\n",
    "\n",
    "x = image_generator.next()\n",
    "y = mask_generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "389d88cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\INSTALL\\anaconda\\envs\\seg\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192/192 [==============================] - 78s 368ms/step - loss: 0.6816 - accuracy: 0.5798 - val_loss: 0.5915 - val_accuracy: 0.9981\n",
      "Epoch 2/25\n",
      "192/192 [==============================] - 72s 373ms/step - loss: 0.6795 - accuracy: 0.5817 - val_loss: 0.5558 - val_accuracy: 1.0000\n",
      "Epoch 3/25\n",
      "192/192 [==============================] - 72s 374ms/step - loss: 0.6794 - accuracy: 0.5817 - val_loss: 0.5406 - val_accuracy: 0.9993\n",
      "Epoch 4/25\n",
      "192/192 [==============================] - 72s 374ms/step - loss: 0.6793 - accuracy: 0.5817 - val_loss: 0.5335 - val_accuracy: 0.9963\n",
      "Epoch 5/25\n",
      "192/192 [==============================] - 72s 374ms/step - loss: 0.6793 - accuracy: 0.5818 - val_loss: 0.5475 - val_accuracy: 0.9998\n",
      "Epoch 6/25\n",
      "192/192 [==============================] - 72s 375ms/step - loss: 0.6792 - accuracy: 0.5818 - val_loss: 0.5630 - val_accuracy: 0.9881\n",
      "Epoch 7/25\n",
      "192/192 [==============================] - 72s 374ms/step - loss: 0.6792 - accuracy: 0.5817 - val_loss: 0.5250 - val_accuracy: 0.9944\n",
      "Epoch 8/25\n",
      "192/192 [==============================] - 72s 377ms/step - loss: 0.6792 - accuracy: 0.5818 - val_loss: 0.5400 - val_accuracy: 0.9673\n",
      "Epoch 9/25\n",
      "192/192 [==============================] - 71s 373ms/step - loss: 0.6791 - accuracy: 0.5821 - val_loss: 0.5477 - val_accuracy: 0.9996\n",
      "Epoch 10/25\n",
      "192/192 [==============================] - 72s 376ms/step - loss: 0.6791 - accuracy: 0.5822 - val_loss: 0.5684 - val_accuracy: 0.9951\n",
      "Epoch 11/25\n",
      "192/192 [==============================] - 72s 374ms/step - loss: 0.6792 - accuracy: 0.5816 - val_loss: 0.5291 - val_accuracy: 0.9989\n",
      "Epoch 12/25\n",
      "192/192 [==============================] - 72s 374ms/step - loss: 0.6791 - accuracy: 0.5820 - val_loss: 0.5271 - val_accuracy: 0.9988\n"
     ]
    }
   ],
   "source": [
    "# define the hyper param\n",
    "\n",
    "import tensorflow.keras as k\n",
    "steps_per_epoch = 3*(len(X_train))//batch_size  # depend on the training dataset\n",
    "\n",
    "callbacks = [\n",
    "    k.callbacks.EarlyStopping(patience=5, monitor='val_loss'),\n",
    "    k.callbacks.TensorBoard(log_dir = 'logs')\n",
    "]\n",
    "\n",
    "history = model.fit_generator(my_generator, validation_data=validation_datagen, \n",
    "                    steps_per_epoch=steps_per_epoch, \n",
    "                    validation_steps=steps_per_epoch, epochs=25, callbacks=callbacks)  # use the model from blocks build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9525819b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the accuracy and loss of the training\n",
    "\n",
    "# loss \n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# accuracy\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "plt.plot(epochs, acc, 'y', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5529aba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IoU socre is:  0.0\n"
     ]
    }
   ],
   "source": [
    "# IOU \n",
    "y_pred=model.predict(X_test)\n",
    "y_pred_thresholded = y_pred > 0.5\n",
    "\n",
    "intersection = np.logical_and(Y_test, y_pred_thresholded)\n",
    "union = np.logical_or(Y_test, y_pred_thresholded)\n",
    "iou_score = np.sum(intersection) / np.sum(union)\n",
    "print(\"IoU socre is: \", iou_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "acdb63ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 256, 256, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (None, 256, 256, 1).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"E:\\INSTALL\\anaconda\\envs\\seg\\lib\\site-packages\\keras\\engine\\training.py\", line 1801, in predict_function  *\n        return step_function(self, iterator)\n    File \"E:\\INSTALL\\anaconda\\envs\\seg\\lib\\site-packages\\keras\\engine\\training.py\", line 1790, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"E:\\INSTALL\\anaconda\\envs\\seg\\lib\\site-packages\\keras\\engine\\training.py\", line 1783, in run_step  **\n        outputs = model.predict_step(data)\n    File \"E:\\INSTALL\\anaconda\\envs\\seg\\lib\\site-packages\\keras\\engine\\training.py\", line 1751, in predict_step\n        return self(x, training=False)\n    File \"E:\\INSTALL\\anaconda\\envs\\seg\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"E:\\INSTALL\\anaconda\\envs\\seg\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 249, in assert_input_compatibility\n        f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Exception encountered when calling layer \"U-Net\" (type Functional).\n    \n    Input 0 of layer \"conv2d\" is incompatible with the layer: expected axis -1 of input shape to have value 3, but received input with shape (None, 256, 256, 1)\n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(None, 256, 256, 1), dtype=float32)\n      • training=False\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7908/292713287.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtest_img_norm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_img\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mtest_img_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_img_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_img_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\INSTALL\\anaconda\\envs\\seg\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\INSTALL\\anaconda\\envs\\seg\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1146\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1147\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1148\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"E:\\INSTALL\\anaconda\\envs\\seg\\lib\\site-packages\\keras\\engine\\training.py\", line 1801, in predict_function  *\n        return step_function(self, iterator)\n    File \"E:\\INSTALL\\anaconda\\envs\\seg\\lib\\site-packages\\keras\\engine\\training.py\", line 1790, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"E:\\INSTALL\\anaconda\\envs\\seg\\lib\\site-packages\\keras\\engine\\training.py\", line 1783, in run_step  **\n        outputs = model.predict_step(data)\n    File \"E:\\INSTALL\\anaconda\\envs\\seg\\lib\\site-packages\\keras\\engine\\training.py\", line 1751, in predict_step\n        return self(x, training=False)\n    File \"E:\\INSTALL\\anaconda\\envs\\seg\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"E:\\INSTALL\\anaconda\\envs\\seg\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 249, in assert_input_compatibility\n        f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Exception encountered when calling layer \"U-Net\" (type Functional).\n    \n    Input 0 of layer \"conv2d\" is incompatible with the layer: expected axis -1 of input shape to have value 3, but received input with shape (None, 256, 256, 1)\n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(None, 256, 256, 1), dtype=float32)\n      • training=False\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "# on test dataset\n",
    "test_img_number = random.randint(0, len(X_test))\n",
    "test_img = X_test[test_img_number]\n",
    "ground_truth=Y_test[test_img_number]\n",
    "test_img_norm=test_img[:,:,0][:,:,None]\n",
    "test_img_input=np.expand_dims(test_img_norm, 0)\n",
    "prediction = (model.predict(test_img_input)[0,:,:,0] > 0.2).astype(np.uint8)\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(231)\n",
    "plt.title('Testing Image')\n",
    "plt.imshow(test_img[:,:,0], cmap='gray')\n",
    "plt.subplot(232)\n",
    "plt.title('Testing Label')\n",
    "plt.imshow(ground_truth[:,:,0], cmap='gray')\n",
    "plt.subplot(233)\n",
    "plt.title('Prediction on test image')\n",
    "plt.imshow(prediction, cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7480071b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
