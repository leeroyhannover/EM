{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### augmentation for the Unet structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the status of GPU\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "local_device_protos = device_lib.list_local_devices()\n",
    "\n",
    "[print(x) for x in local_device_protos if x.device_type == 'GPU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/leeleeroy/UNet-2D-EM/e/UN-22\n",
      "Remember to stop your run once you’ve finished logging your metadata (https://docs.neptune.ai/api-reference/run#.stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/li52/.local/lib/python3.6/site-packages/neptune/new/internal/utils/git.py:35: UserWarning: GitPython could not be initialized\n",
      "  warnings.warn(\"GitPython could not be initialized\")\n",
      "/home/li52/.local/lib/python3.6/site-packages/neptune/new/internal/utils/git.py:35: UserWarning: GitPython could not be initialized\n",
      "  warnings.warn(\"GitPython could not be initialized\")\n"
     ]
    }
   ],
   "source": [
    "# neptune document\n",
    "\n",
    "import neptune.new as neptune\n",
    "\n",
    "run = neptune.init(\n",
    "    project='leeleeroy/UNet-2D-EM',\n",
    "    api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiI3YjVjOGVmZi04MjA4LTQ4N2QtOWIzYy05M2YyZWI1NzY3MmEifQ==\",\n",
    "    name = \"UNet2D_256_aug\",  \n",
    ")  # necessary credentials, the name could be used to reproduce the results \n",
    "\n",
    "\n",
    "# for callbacks in training\n",
    "\n",
    "from neptune.new.integrations.tensorflow_keras import NeptuneCallback\n",
    "\n",
    "neptune_cbk = NeptuneCallback(run=run, base_namespace='metrics')  # neptune for the training process\n",
    "# neptune document the hyper param.\n",
    "\n",
    "PARAMS = {'patchify': 256,\n",
    "          \"optimizer\": {\"learning_rate\": 0.001, \"beta_1\":0.9,\"optimizer\": \"Adam\"},\n",
    "          'epochs':100,\n",
    "          'batch_size':8}\n",
    "\n",
    "# log hyper-parameters\n",
    "run['hyper-parameters'] = PARAMS\n",
    "run[\"sys/tags\"].add([\"model-type: \", \"2D_256\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading \n",
    "\n",
    "import os\n",
    "import mrcfile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "from tqdm import tqdm  # ! this might result into problem with 'object'\n",
    "import os\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]/home/li52/.local/lib/python3.6/site-packages/mrcfile/mrcinterpreter.py:219: RuntimeWarning: Unrecognised machine stamp: 0x00 0x00 0x00 0x00\n",
      "  warnings.warn(str(err), RuntimeWarning)\n",
      " 67%|██████▋   | 2/3 [00:00<00:00,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tomo2_focalseries.mrc\n",
      "tomo3_focalseries.mrc\n",
      "tomo1_focalseries.mrc\n",
      "tomo2_groundtruth.mrc\n",
      "tomo3_groundtruth.mrc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  3.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tomo1_groundtruth.mrc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def readMRC(path):\n",
    "    with mrcfile.open(path, mode='r+', permissive=True) as mrc:\n",
    "        mrc.header.map = mrcfile.constants.MAP_ID # for synthetic data, need to generate ID\n",
    "        data = mrc.data\n",
    "    return data\n",
    "\n",
    "DATA_PATH = './synthetic/'  # in hemera, only use relative path\n",
    "data_ids = next(os.walk(DATA_PATH))[1]\n",
    "raw = []\n",
    "for n, id_ in tqdm(enumerate(data_ids), total=len(data_ids)):  \n",
    "    path = DATA_PATH + id_\n",
    "    datanames = os.listdir(path)\n",
    "    for dataname in datanames:\n",
    "        if os.path.splitext(dataname)[1] == '.mrc': # all .mrc under the path\n",
    "            temp = readMRC(path + \"/\" + dataname).astype(np.uint8)\n",
    "            raw.append(temp)\n",
    "            print(dataname)\n",
    "            \n",
    "focal = raw[0:3]\n",
    "GT = raw[3:len(raw)]\n",
    "del raw, temp, datanames, dataname, path, data_ids, n, id_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 256, 256)\n",
      "(512, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "# raw data sorting: padding, reshape\n",
    "\n",
    "import torchio as tio\n",
    "from patchify import patchify, unpatchify\n",
    "\n",
    "# training dataset raw\n",
    "train_raw = np.vstack(([focal[0], focal[1]]));train = train_raw[...,np.newaxis].transpose((3,1,2,0)); label = np.vstack(([GT[0], GT[1]]))#;label = train_label[...,np.newaxis]\n",
    "\n",
    "trainIO = tio.ScalarImage(tensor=train)\n",
    "target_shape = 256,256,512  # padding into the same size\n",
    "crop_pad = tio.CropOrPad(target_shape, padding_mode='mean'); resized = crop_pad(trainIO) # padding with mean\n",
    "train_padd = resized.numpy().transpose((3,1,2,0)); train_padd = train_padd[...,0]\n",
    "print(train_padd.shape);print(label.shape)\n",
    "\n",
    "# testing dataset raw\n",
    "X_test = focal[2]; X_test = X_test[...,np.newaxis].transpose((3,1,2,0))\n",
    "Y_test_label = GT[2]; Y_test_label = (Y_test_label > 0.5).astype(np.float) \n",
    "\n",
    "testIO = tio.ScalarImage(tensor=X_test)\n",
    "target_shape = 256,256,256\n",
    "crop_pad = tio.CropOrPad(target_shape, padding_mode='mean'); resized = crop_pad(testIO)\n",
    "test_padd = resized.numpy().transpose((3,1,2,0)); test_padd = test_padd[...,0];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patchify the images\n",
    "\n",
    "def rawPatch(imageStack,patchPara):\n",
    "    all_img_patches = []\n",
    "\n",
    "    for img in range(imageStack.shape[0]):\n",
    "        large_image = imageStack[img]\n",
    "\n",
    "        patches_img = patchify(large_image, (patchPara['x'],patchPara['y']), step=patchPara['step'])  # no overlap\n",
    "\n",
    "        for i in range(patches_img.shape[0]):\n",
    "            for j in range(patches_img.shape[1]):\n",
    "\n",
    "                single_patch_img = patches_img[i,j,:,:]\n",
    "                single_patch_img = (single_patch_img.astype('float32')) / 255.  # remember to standarize into 0-1\n",
    "\n",
    "                all_img_patches.append(single_patch_img)\n",
    "    \n",
    "    return all_img_patches, patches_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256, 256, 3)\n",
      "(256, 256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "# train dataset\n",
    "patchPara = {'x': 256, 'y': 256, 'step':256}\n",
    "Xtrain_patches, _ = rawPatch(train_padd, patchPara);Xtrain_patches = np.stack((Xtrain_patches,)*3, axis=-1) # dock 3 times, the model expects 3 channel\n",
    "# print(Xtrain_patches.shape)\n",
    "\n",
    "Ytrain_patches, _ = rawPatch(label, patchPara);Ytrain_patches = np.expand_dims(Ytrain_patches, -1)\n",
    "Ytrain_patches = (Ytrain_patches > 0.5).astype(np.float) # binarize the data\n",
    "\n",
    "# test dataset\n",
    "Xtest_patches, patchSize = rawPatch(test_padd, patchPara);Xtest_patches = np.stack((Xtest_patches,)*3, axis=-1)\n",
    "Ytest_patches, _ = rawPatch(Y_test_label, patchPara);Ytest_patches = np.expand_dims(Ytest_patches, -1)\n",
    "Ytest_patches = (Ytest_patches > 0.5).astype(np.float)\n",
    "print(Xtest_patches.shape);print(Ytest_patches.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Unet structure in blocks\n",
    "import tensorflow.keras as k\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\n",
    "from tensorflow.keras.optimizers import Adam  # ! notice here must write in tensorflow.keras\n",
    "from keras.layers import Activation, MaxPool2D, Concatenate\n",
    "\n",
    "\n",
    "def conv_block(input, num_filters):\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(input)\n",
    "    x = BatchNormalization()(x)   #Not in the original network. \n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)  #Not in the original network\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "#Encoder block: Conv block followed by maxpooling\n",
    "\n",
    "def encoder_block(input, num_filters):\n",
    "    x = conv_block(input, num_filters)\n",
    "    p = MaxPool2D((2, 2))(x)\n",
    "    return x, p   \n",
    "\n",
    "#Decoder block\n",
    "#skip features gets input from encoder for concatenation\n",
    "\n",
    "def decoder_block(input, skip_features, num_filters):\n",
    "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n",
    "    x = Concatenate()([x, skip_features])\n",
    "    x = conv_block(x, num_filters)\n",
    "    return x\n",
    "\n",
    "#Build Unet using the blocks\n",
    "def build_unet(input_shape):\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    s1, p1 = encoder_block(inputs, 64)\n",
    "    s2, p2 = encoder_block(p1, 128)\n",
    "    s3, p3 = encoder_block(p2, 256)\n",
    "    s4, p4 = encoder_block(p3, 512)\n",
    "\n",
    "    b1 = conv_block(p4, 1024) #Bridge\n",
    "\n",
    "    d1 = decoder_block(b1, s4, 512)\n",
    "    d2 = decoder_block(d1, s3, 256)\n",
    "    d3 = decoder_block(d2, s2, 128)\n",
    "    d4 = decoder_block(d3, s1, 64)\n",
    "\n",
    "    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)  #Binary (can be multiclass)\n",
    "\n",
    "    model = Model(inputs, outputs, name=\"U-Net\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "input_shape = (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n",
    "\n",
    "model = build_unet(input_shape)\n",
    "model.compile(optimizer=Adam(lr = 1e-3), loss='binary_crossentropy', metrics=['accuracy'])  # add Adam from Keras, not tensorflow.adam\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data augmentation\n",
    "\n",
    "seed=24  # gurantee the images and masks are the same with augmentaion\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# dictionary for augmentation\n",
    "img_data_gen_args = dict(rotation_range=90,\n",
    "                     width_shift_range=0.3,\n",
    "                     height_shift_range=0.3,\n",
    "                     shear_range=0.5,\n",
    "                     zoom_range=0.3,\n",
    "                     horizontal_flip=True,\n",
    "                     vertical_flip=True,\n",
    "                     fill_mode='reflect')\n",
    "\n",
    "mask_data_gen_args = dict(rotation_range=90,\n",
    "                     width_shift_range=0.3,\n",
    "                     height_shift_range=0.3,\n",
    "                     shear_range=0.5,\n",
    "                     zoom_range=0.3,\n",
    "                     horizontal_flip=True,\n",
    "                     vertical_flip=True,\n",
    "                     fill_mode='reflect',\n",
    "                     preprocessing_function = lambda x: np.where(x>0, 1, 0).astype(x.dtype)) \n",
    "#Binarize the output again. Because the new-generated images comes with interperated values\n",
    "\n",
    "image_data_generator = ImageDataGenerator(**img_data_gen_args)\n",
    "\n",
    "\n",
    "batch_size= 8  # 16 will dead\n",
    "\n",
    "X_train = Xtrain_patches; Y_train = Ytrain_patches;\n",
    "X_test = Xtest_patches; Y_test = Ytest_patches;\n",
    "image_generator = image_data_generator.flow(X_train, seed=seed, batch_size=batch_size)\n",
    "valid_img_generator = image_data_generator.flow(X_test, seed=seed, batch_size=batch_size) #Default batch size 32, if not specified here\n",
    "\n",
    "mask_data_generator = ImageDataGenerator(**mask_data_gen_args)\n",
    "mask_generator = mask_data_generator.flow(Y_train, seed=seed, batch_size=batch_size)  # the seed is same\n",
    "valid_mask_generator = mask_data_generator.flow(Y_test, seed=seed, batch_size=batch_size)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# 另外的处理数据的方式\n",
    "# image_data_generator = ImageDataGenerator(**img_data_gen_args)\n",
    "# image_data_generator.fit(X_train, augment=True, seed=seed)\n",
    "\n",
    "# image_generator = image_data_generator.flow(X_train, seed=seed)\n",
    "# valid_img_generator = image_data_generator.flow(X_test, seed=seed)\n",
    "\n",
    "# mask_data_generator = ImageDataGenerator(**mask_data_gen_args)\n",
    "# mask_data_generator.fit(y_train, augment=True, seed=seed)\n",
    "# mask_generator = mask_data_generator.flow(y_train, seed=seed)\n",
    "# valid_mask_generator = mask_data_generator.flow(y_test, seed=seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_image_mask_generator(image_generator, mask_generator):\n",
    "    train_generator = zip(image_generator, mask_generator)\n",
    "    for (img, mask) in train_generator:\n",
    "        yield (img, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator\n",
    "\n",
    "my_generator = my_image_mask_generator(image_generator, mask_generator)  # give out the image generator and mask at teh same time\n",
    "\n",
    "validation_datagen = my_image_mask_generator(valid_img_generator, valid_mask_generator)\n",
    "\n",
    "x = image_generator.next()\n",
    "y = mask_generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "  3/192 [..............................] - ETA: 3:50:54 - loss: 0.7802 - acc: 0.4923"
     ]
    }
   ],
   "source": [
    "# define the hyper param\n",
    "\n",
    "import tensorflow.keras as k\n",
    "steps_per_epoch = 3*(len(X_train))//batch_size  # depend on the training dataset\n",
    "\n",
    "callbacks = [\n",
    "    #k.callbacks.EarlyStopping(patience=10, monitor='val_loss'),\n",
    "    neptune_cbk,\n",
    "    k.callbacks.TensorBoard(log_dir = 'logsAugH')\n",
    "]\n",
    "\n",
    "history = model.fit_generator(my_generator, validation_data=validation_datagen, \n",
    "                    steps_per_epoch=steps_per_epoch, \n",
    "                    validation_steps=steps_per_epoch, epochs=2, callbacks=callbacks)  # use the model from blocks build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the accuracy and loss of the training\n",
    "\n",
    "# loss \n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# accuracy\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "plt.plot(epochs, acc, 'y', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IOU \n",
    "y_pred=model.predict(X_test)\n",
    "y_pred_thresholded = y_pred > 0.5\n",
    "\n",
    "intersection = np.logical_and(Y_test, y_pred_thresholded)\n",
    "union = np.logical_or(Y_test, y_pred_thresholded)\n",
    "iou_score = np.sum(intersection) / np.sum(union)\n",
    "print(\"IoU socre is: \", iou_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on test dataset\n",
    "test_img_number = random.randint(0, len(X_test))\n",
    "test_img = X_test[test_img_number]\n",
    "ground_truth=Y_test[test_img_number]\n",
    "test_img_norm=test_img[:,:,0][:,:,None]\n",
    "test_img_input=np.expand_dims(test_img_norm, 0)\n",
    "prediction = (model.predict(test_img_input)[0,:,:,0] > 0.2).astype(np.uint8)\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(231)\n",
    "plt.title('Testing Image')\n",
    "plt.imshow(test_img[:,:,0], cmap='gray')\n",
    "plt.subplot(232)\n",
    "plt.title('Testing Label')\n",
    "plt.imshow(ground_truth[:,:,0], cmap='gray')\n",
    "plt.subplot(233)\n",
    "plt.title('Prediction on test image')\n",
    "plt.imshow(prediction, cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'run' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-fb6b2c96574f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# stop logging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'run' is not defined"
     ]
    }
   ],
   "source": [
    "run.stop()  # stop logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
