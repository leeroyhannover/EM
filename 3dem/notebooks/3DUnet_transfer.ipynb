{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3D Unet using tranfer learning of VGG16 on first sythetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-28 23:50:31.529363: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 31596363136\n",
      "locality {\n",
      "  bus_id: 2\n",
      "  numa_node: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 18256467481345515402\n",
      "physical_device_desc: \"device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:89:00.0, compute capability: 7.0\"\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-28 23:50:52.058333: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-28 23:50:52.075278: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-04-28 23:50:52.180924: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:89:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2022-04-28 23:50:52.180971: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-04-28 23:50:52.516002: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-04-28 23:50:52.516091: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-04-28 23:50:52.721489: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-04-28 23:50:52.808379: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-04-28 23:50:53.071935: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-04-28 23:50:53.184246: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-04-28 23:50:53.876645: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-04-28 23:50:53.877699: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-04-28 23:50:53.877746: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-04-28 23:51:00.265355: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-04-28 23:51:00.265391: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2022-04-28 23:51:00.265412: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2022-04-28 23:51:00.267549: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/device:GPU:0 with 30132 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:89:00.0, compute capability: 7.0)\n",
      "2022-04-28 23:51:00.296679: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the status of GPU\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "local_device_protos = device_lib.list_local_devices()\n",
    "\n",
    "[print(x) for x in local_device_protos if x.device_type == 'GPU']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install classification-models-3D\n",
    "# !pip install efficientnet-3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOCUMENT = True\n",
    "TRAIN = 500  # 训练的数目"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/leeleeroy/UNet-3D-EM/e/UN1-8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/li52/.conda/envs/seg/lib/python3.7/site-packages/neptune/new/internal/utils/git.py:35: UserWarning: GitPython could not be initialized\n",
      "  warnings.warn(\"GitPython could not be initialized\")\n",
      "/home/li52/.conda/envs/seg/lib/python3.7/site-packages/neptune/new/internal/utils/git.py:35: UserWarning: GitPython could not be initialized\n",
      "  warnings.warn(\"GitPython could not be initialized\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remember to stop your run once you’ve finished logging your metadata (https://docs.neptune.ai/api-reference/run#.stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n"
     ]
    }
   ],
   "source": [
    "# neptune document\n",
    "\n",
    "import neptune.new as neptune\n",
    "from neptune.new.integrations.tensorflow_keras import NeptuneCallback\n",
    "\n",
    "if DOCUMENT:\n",
    "\n",
    "    run = neptune.init(\n",
    "        project=\"leeleeroy/UNet-3D-EM\",\n",
    "        api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiI3YjVjOGVmZi04MjA4LTQ4N2QtOWIzYy05M2YyZWI1NzY3MmEifQ==\",\n",
    "        name = \"UNet3D_64_vgg16\",\n",
    "    ) # necessary credentials, the name could be used to reproduce the results \n",
    "\n",
    "    # for callbacks in training\n",
    "\n",
    "\n",
    "\n",
    "    neptune_cbk = NeptuneCallback(run=run, base_namespace='metrics')  # neptune for the training process\n",
    "    \n",
    "    # neptune document the hyper param.\n",
    "\n",
    "    PARAMS = {'patchify': 64,\n",
    "              \"optimizer\": {\"learning_rate\": 0.001, \"beta_1\":0.9,\"optimizer\": \"Adam\"},\n",
    "              'epochs': TRAIN,\n",
    "              'batch_size':8}\n",
    "\n",
    "    # log hyper-parameters\n",
    "    run['hyper-parameters'] = PARAMS\n",
    "    run[\"sys/tags\"].add([\"3D_64\",\"transfer\", \"vgg16\", \"val\", \"test\", \"500\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### read in the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `tf.keras` framework.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mrcfile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "from tqdm import tqdm  # ! this might result into problem with 'object'\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras as k\n",
    "import segmentation_models_3D as sm\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from skimage import io\n",
    "from patchify import patchify, unpatchify\n",
    "from sklearn.model_selection import train_test_split\n",
    "# import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]/home/li52/.conda/envs/seg/lib/python3.7/site-packages/mrcfile/mrcinterpreter.py:219: RuntimeWarning: Unrecognised machine stamp: 0x00 0x00 0x00 0x00\n",
      "  warnings.warn(str(err), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tomo2_focalseries.mrc\n",
      "tomo3_focalseries.mrc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:00<00:00,  5.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tomo1_focalseries.mrc\n",
      "tomo2_groundtruth.mrc\n",
      "tomo3_groundtruth.mrc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tomo1_groundtruth.mrc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def readMRC(path):\n",
    "    with mrcfile.open(path, mode='r+', permissive=True) as mrc:\n",
    "        mrc.header.map = mrcfile.constants.MAP_ID # for synthetic data, need to generate ID\n",
    "        data = mrc.data\n",
    "    return data\n",
    "\n",
    "# DATA_PATH = 'F:/MDC/4.1dataAugNeat/EM/3dem/data/interim/synthetic/'\n",
    "DATA_PATH = './synthetic/'  # in hemera, only use relative path\n",
    "data_ids = next(os.walk(DATA_PATH))[1]\n",
    "raw = []\n",
    "for n, id_ in tqdm(enumerate(data_ids), total=len(data_ids)):  \n",
    "    path = DATA_PATH + id_\n",
    "    datanames = os.listdir(path)\n",
    "    for dataname in datanames:\n",
    "        if os.path.splitext(dataname)[1] == '.mrc': # all .mrc under the path\n",
    "            temp = readMRC(path + \"/\" + dataname).astype(np.uint8)\n",
    "            raw.append(temp)\n",
    "            print(dataname)\n",
    "            \n",
    "focal = raw[0:3]\n",
    "GT = raw[3:len(raw)]\n",
    "del raw, temp, datanames, dataname, path, data_ids, n, id_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check for the data type\n",
    "\n",
    "# test = focal[0]\n",
    "# print(test.dtype, test.shape)\n",
    "# test1 = test[0,...]\n",
    "# print(test1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/li52/.conda/envs/seg/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 256, 256)\n",
      "(512, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "# raw data sorting: padding, reshape\n",
    "\n",
    "import torchio as tio\n",
    "from patchify import patchify, unpatchify\n",
    "\n",
    "# training dataset raw\n",
    "train_raw = np.vstack(([focal[0], focal[1]]));train = train_raw[...,np.newaxis].transpose((3,1,2,0)); label = np.vstack(([GT[0], GT[1]]))#;label = train_label[...,np.newaxis]\n",
    "\n",
    "trainIO = tio.ScalarImage(tensor=train)\n",
    "target_shape = 256,256,512  # padding into the same size\n",
    "crop_pad = tio.CropOrPad(target_shape, padding_mode='mean'); resized = crop_pad(trainIO) # padding with mean\n",
    "train_padd = resized.numpy().transpose((3,1,2,0)); train_padd = train_padd[...,0]\n",
    "print(train_padd.shape);print(label.shape)\n",
    "\n",
    "# testing dataset raw\n",
    "X_test = focal[2]; X_test = X_test[...,np.newaxis].transpose((3,1,2,0))\n",
    "Y_test_label = GT[2]\n",
    "# Y_test_label = (Y_test_label > 0.5).astype(np.float) # 这里不要做二元化，下面再做二元化\n",
    "\n",
    "testIO = tio.ScalarImage(tensor=X_test)\n",
    "target_shape = 256,256,256\n",
    "crop_pad = tio.CropOrPad(target_shape, padding_mode='mean'); resized = crop_pad(testIO)\n",
    "test_padd = resized.numpy().transpose((3,1,2,0)); test_padd = test_padd[...,0];\n",
    "\n",
    "testStackSize = test_padd.shape  # document the original size of image stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_test.dtype, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint8 float64\n",
      "(4, 4, 4, 64, 64, 64) (4, 4, 4, 64, 64, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/li52/.conda/envs/seg/lib/python3.7/site-packages/ipykernel_launcher.py:9: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  if __name__ == '__main__':\n",
      "/home/li52/.conda/envs/seg/lib/python3.7/site-packages/ipykernel_launcher.py:12: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "# pre-processing the data: scaling, binarize \n",
    "\n",
    "X_train = train_padd; Y_train = label\n",
    "\n",
    "X_test_raw = test_padd; Y_test_raw = Y_test_label\n",
    "\n",
    "# binary the mask here\n",
    "# X_train = (X_train / 255.).astype(np.float)  # 不需要scale，之后的会在进行scale\n",
    "Y_train = ((Y_train / 255) > 0.5).astype(np.float)\n",
    "\n",
    "# X_test = (X_test / 255.).astype(np.float)\n",
    "Y_test = ((Y_test_raw / 255) > 0.5).astype(np.float)\n",
    "\n",
    "print(X_train.dtype, Y_train.dtype)\n",
    "\n",
    "# patchify the training data\n",
    "img_patches = patchify(X_train, (64, 64, 64), step=64)  #Step=64 for 64 patches means no overlap\n",
    "mask_patches = patchify(Y_train, (64, 64, 64), step=64)  \n",
    "unpatchParaTrain = img_patches.shape\n",
    "\n",
    "# patchify the test data\n",
    "test_img_patches = patchify(X_test_raw, (64, 64, 64), step=64) \n",
    "test_mask_patches = patchify(Y_test_raw, (64, 64, 64), step=64) \n",
    "unpatchParaTest = test_img_patches.shape\n",
    "\n",
    "print(test_mask_patches.shape, test_img_patches.shape)\n",
    "# print(X_test_raw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint8 float64\n"
     ]
    }
   ],
   "source": [
    "# sanity check for the data type\n",
    "\n",
    "print(X_test.dtype, Y_test.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2aac5a505390>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sanity check\n",
    "\n",
    "plt.imshow(img_patches[1,2,3,32,:,:], cmap='gray')  # 注意交换过次序，第一维表示图片\n",
    "plt.figure();plt.imshow(mask_patches[1,2,3,32,:,:], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 64, 64)\n",
      "(64, 64, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "# flatten the patches\n",
    "\n",
    "input_img = np.reshape(img_patches, (-1, unpatchParaTrain[3], unpatchParaTrain[4], unpatchParaTrain[5]))\n",
    "input_mask = np.reshape(mask_patches, (-1, unpatchParaTrain[3], unpatchParaTrain[4], unpatchParaTrain[5]))\n",
    "\n",
    "X_test = np.reshape(test_img_patches, (-1, unpatchParaTest[3], unpatchParaTest[4], unpatchParaTest[5]))\n",
    "Y_test = np.reshape(test_mask_patches, (-1, unpatchParaTest[3], unpatchParaTest[4], unpatchParaTest[5]))\n",
    "\n",
    "print(X_test.shape)  # n_patches, x, y, z\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 64) uint8\n",
      "[[125 147  90 ... 131 117  98]\n",
      " [148 141 129 ... 142 147 109]\n",
      " [158 109 104 ... 147 127 130]\n",
      " ...\n",
      " [148 129  99 ... 131 128 127]\n",
      " [117 150 153 ... 133 118 106]\n",
      " [144 132 106 ... 115 108  92]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sanity check the order\n",
    "\n",
    "test1 = X_test[0,...]\n",
    "print(test1.shape, test1.dtype)\n",
    "plt.imshow(test1[0,...], cmap='gray')\n",
    "print(test1[0,...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train img: (128, 64, 64, 64, 3) train mask: (128, 64, 64, 64, 1)\n",
      "test img: (64, 64, 64, 64, 3) test mask: (64, 64, 64, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "# preprocessing the img into RGB 3 channel\n",
    "n_classes = 2   # many classes by the final segmentation # 需要二元化mask才能做分类\n",
    "\n",
    "train_img = np.stack((input_img,)*3, axis=-1)\n",
    "train_mask = np.expand_dims(input_mask, axis=4) # expand one version\n",
    "print('train img:', train_img.shape, 'train mask:', train_mask.shape)\n",
    "\n",
    "# pre-processing for the test image\n",
    "\n",
    "X_test = np.stack((X_test,)*3, axis=-1)\n",
    "Y_test = np.expand_dims(Y_test, axis=4) # expand one version\n",
    "print('test img:', X_test.shape, 'test mask:', Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. ... 1. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# sanity check for the binary of training mask\n",
    "\n",
    "test = train_mask[0,...]\n",
    "print(test[0,:,:,0])\n",
    "# print(X_test[0,0,...])  # still 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-processing the data into categories\n",
    "\n",
    "train_mask_cat = to_categorical(train_mask, num_classes=n_classes) # trun into the sorts. transform last dimension into 2\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(train_img, train_mask_cat, test_size = 0.25, random_state = 0) # Slitting into validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 64, 64, 64, 3)\n",
      "before pre: 0 255\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape) #[0,0,...]\n",
    "# print(X_train[0,0,...])  # 此时的状态是正确的\n",
    "print('before pre:', np.min(X_train), np.max(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the loss\n",
    "\n",
    "# careful with the focal loss\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    smoothing_factor = 1\n",
    "    flat_y_true = K.flatten(y_true)\n",
    "    flat_y_pred = K.flatten(y_pred)\n",
    "    return (2. * K.sum(flat_y_true * flat_y_pred) + smoothing_factor) / (K.sum(flat_y_true) + K.sum(flat_y_pred) + smoothing_factor)  # 损失函数\n",
    "\n",
    "def dice_coefficient_loss(y_true, y_pred):\n",
    "    return 1 - dice_coefficient(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper param of the models\n",
    "\n",
    "encoder_weights = 'imagenet'\n",
    "BACKBONE = 'vgg16'  # other available models: vgg16, efficientnetb7, inceptionv3, resnet50\n",
    "AKTIV = 'softmax'  \n",
    "patch_size = 64\n",
    "n_classes = 2\n",
    "channels=3\n",
    "\n",
    "LR = 0.0001\n",
    "optim = k.optimizers.Adam(LR)\n",
    "\n",
    "# Segmentation models losses can be combined together by '+' and scaled by integer or float factor\n",
    "# set class weights for dice_loss (car: 1.; pedestrian: 2.; background: 0.5;)\n",
    "dice_loss = sm.losses.DiceLoss(class_weights=np.array([0.5, 0.5])) # weights for segmentation classes\n",
    "focal_loss = sm.losses.CategoricalFocalLoss()  # handiling the inbalance dataset\n",
    "total_loss = dice_loss + (1 * focal_loss)\n",
    "\n",
    "# actulally total_loss can be imported directly from library, above example just show you how to manipulate with losses\n",
    "# total_loss = sm.losses.binary_focal_dice_loss # or sm.losses.categorical_focal_dice_loss \n",
    "\n",
    "metrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5)]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-28 23:51:29.597818: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
      "2022-04-28 23:51:29.597847: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n",
      "2022-04-28 23:51:29.610761: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1365] Profiler found 1 GPUs\n",
      "2022-04-28 23:51:29.798095: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcupti.so.10.1\n",
      "2022-04-28 23:51:29.898675: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1415] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_INSUFFICIENT_PRIVILEGES\n",
      "2022-04-28 23:51:29.898910: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n"
     ]
    }
   ],
   "source": [
    "# define the callback \n",
    "\n",
    "# setting checkpoints\n",
    "checkpointer = k.callbacks.ModelCheckpoint('./transfer3D/model/3d_unet_transfer.h5', verbose=1, save_best_only=True)\n",
    "\n",
    "if DOCUMENT:\n",
    "    callbacks = [\n",
    "        #k.callbacks.EarlyStopping(patience=10, monitor='val_loss'),\n",
    "        neptune_cbk, \n",
    "        k.callbacks.TensorBoard(log_dir = './transfer3D/tensorBoard')  # save in new folder in hemera. Also update in neptune\n",
    "    ]\n",
    "else:\n",
    "    callbacks = [\n",
    "        #k.callbacks.EarlyStopping(patience=10, monitor='val_loss'),\n",
    "        k.callbacks.TensorBoard(log_dir = './transfer3D/tensorBoard')  # save in new folder in hemera. Also update in neptune\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 64, 64, 64, 3) (32, 64, 64, 64, 3) (96, 64, 64, 64, 2)\n",
      "(64, 64, 64, 3)\n",
      "-123.68\n",
      "before pre: 0 255\n",
      "after pre: -123.68 151.061\n"
     ]
    }
   ],
   "source": [
    "# preprocess the training data\n",
    "\n",
    "preprocess_input = sm.get_preprocessing(BACKBONE)\n",
    "X_train_prep = preprocess_input(X_train)  # scale the dataset\n",
    "X_val_prep = preprocess_input(X_val)\n",
    "\n",
    "print(X_train_prep.shape, X_val_prep.shape, Y_train.shape)\n",
    "\n",
    "testImg = X_train_prep[0,...]; testMask = Y_train[0,...]\n",
    "print(testImg.shape)\n",
    "print(np.min(testImg[0,...]))  # 这之后数值rescale了\n",
    "print('before pre:', np.min(X_train), np.max(X_train))\n",
    "print('after pre:', np.min(X_train_prep), np.max(X_train_prep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-28 23:51:30.519763: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-04-28 23:51:30.520394: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:89:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2022-04-28 23:51:30.520428: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-04-28 23:51:30.520453: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-04-28 23:51:30.520464: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-04-28 23:51:30.520474: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-04-28 23:51:30.520485: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-04-28 23:51:30.520495: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-04-28 23:51:30.520505: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-04-28 23:51:30.520515: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-04-28 23:51:30.521309: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-04-28 23:51:30.522008: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:89:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2022-04-28 23:51:30.522039: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-04-28 23:51:30.522057: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-04-28 23:51:30.522066: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-04-28 23:51:30.522075: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-04-28 23:51:30.522083: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-04-28 23:51:30.522092: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-04-28 23:51:30.522101: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-04-28 23:51:30.522110: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-04-28 23:51:30.522881: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-04-28 23:51:30.522913: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-04-28 23:51:30.522919: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2022-04-28 23:51:30.522924: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2022-04-28 23:51:30.523731: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30132 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:89:00.0, compute capability: 7.0)\n",
      "2022-04-28 23:51:30.523747: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 64, 64, 64,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv3D)           (None, 64, 64, 64, 6 5248        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv3D)           (None, 64, 64, 64, 6 110656      block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling3D)      (None, 32, 32, 32, 6 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv3D)           (None, 32, 32, 32, 1 221312      block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv3D)           (None, 32, 32, 32, 1 442496      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling3D)      (None, 16, 16, 16, 1 0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv3D)           (None, 16, 16, 16, 2 884992      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv3D)           (None, 16, 16, 16, 2 1769728     block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv3D)           (None, 16, 16, 16, 2 1769728     block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling3D)      (None, 8, 8, 8, 256) 0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv3D)           (None, 8, 8, 8, 512) 3539456     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv3D)           (None, 8, 8, 8, 512) 7078400     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv3D)           (None, 8, 8, 8, 512) 7078400     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling3D)      (None, 4, 4, 4, 512) 0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv3D)           (None, 4, 4, 4, 512) 7078400     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv3D)           (None, 4, 4, 4, 512) 7078400     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv3D)           (None, 4, 4, 4, 512) 7078400     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling3D)      (None, 2, 2, 2, 512) 0           block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_block1_conv (Conv3D)     (None, 2, 2, 2, 512) 7077888     block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "center_block1_bn (BatchNormaliz (None, 2, 2, 2, 512) 2048        center_block1_conv[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_block1_relu (Activation) (None, 2, 2, 2, 512) 0           center_block1_bn[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "center_block2_conv (Conv3D)     (None, 2, 2, 2, 512) 7077888     center_block1_relu[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_block2_bn (BatchNormaliz (None, 2, 2, 2, 512) 2048        center_block2_conv[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_block2_relu (Activation) (None, 2, 2, 2, 512) 0           center_block2_bn[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0_upsampling (UpSa (None, 4, 4, 4, 512) 0           center_block2_relu[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0_concat (Concaten (None, 4, 4, 4, 1024 0           decoder_stage0_upsampling[0][0]  \n",
      "                                                                 block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0a_conv (Conv3D)   (None, 4, 4, 4, 256) 7077888     decoder_stage0_concat[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0a_bn (BatchNormal (None, 4, 4, 4, 256) 1024        decoder_stage0a_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0a_relu (Activatio (None, 4, 4, 4, 256) 0           decoder_stage0a_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0b_conv (Conv3D)   (None, 4, 4, 4, 256) 1769472     decoder_stage0a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0b_bn (BatchNormal (None, 4, 4, 4, 256) 1024        decoder_stage0b_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0b_relu (Activatio (None, 4, 4, 4, 256) 0           decoder_stage0b_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1_upsampling (UpSa (None, 8, 8, 8, 256) 0           decoder_stage0b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1_concat (Concaten (None, 8, 8, 8, 768) 0           decoder_stage1_upsampling[0][0]  \n",
      "                                                                 block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1a_conv (Conv3D)   (None, 8, 8, 8, 128) 2654208     decoder_stage1_concat[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1a_bn (BatchNormal (None, 8, 8, 8, 128) 512         decoder_stage1a_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1a_relu (Activatio (None, 8, 8, 8, 128) 0           decoder_stage1a_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1b_conv (Conv3D)   (None, 8, 8, 8, 128) 442368      decoder_stage1a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1b_bn (BatchNormal (None, 8, 8, 8, 128) 512         decoder_stage1b_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1b_relu (Activatio (None, 8, 8, 8, 128) 0           decoder_stage1b_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2_upsampling (UpSa (None, 16, 16, 16, 1 0           decoder_stage1b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2_concat (Concaten (None, 16, 16, 16, 3 0           decoder_stage2_upsampling[0][0]  \n",
      "                                                                 block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2a_conv (Conv3D)   (None, 16, 16, 16, 6 663552      decoder_stage2_concat[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2a_bn (BatchNormal (None, 16, 16, 16, 6 256         decoder_stage2a_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2a_relu (Activatio (None, 16, 16, 16, 6 0           decoder_stage2a_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2b_conv (Conv3D)   (None, 16, 16, 16, 6 110592      decoder_stage2a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2b_bn (BatchNormal (None, 16, 16, 16, 6 256         decoder_stage2b_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2b_relu (Activatio (None, 16, 16, 16, 6 0           decoder_stage2b_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3_upsampling (UpSa (None, 32, 32, 32, 6 0           decoder_stage2b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3_concat (Concaten (None, 32, 32, 32, 1 0           decoder_stage3_upsampling[0][0]  \n",
      "                                                                 block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3a_conv (Conv3D)   (None, 32, 32, 32, 3 165888      decoder_stage3_concat[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3a_bn (BatchNormal (None, 32, 32, 32, 3 128         decoder_stage3a_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3a_relu (Activatio (None, 32, 32, 32, 3 0           decoder_stage3a_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3b_conv (Conv3D)   (None, 32, 32, 32, 3 27648       decoder_stage3a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3b_bn (BatchNormal (None, 32, 32, 32, 3 128         decoder_stage3b_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3b_relu (Activatio (None, 32, 32, 32, 3 0           decoder_stage3b_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4_upsampling (UpSa (None, 64, 64, 64, 3 0           decoder_stage3b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4a_conv (Conv3D)   (None, 64, 64, 64, 1 13824       decoder_stage4_upsampling[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4a_bn (BatchNormal (None, 64, 64, 64, 1 64          decoder_stage4a_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4a_relu (Activatio (None, 64, 64, 64, 1 0           decoder_stage4a_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4b_conv (Conv3D)   (None, 64, 64, 64, 1 6912        decoder_stage4a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4b_bn (BatchNormal (None, 64, 64, 64, 1 64          decoder_stage4b_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4b_relu (Activatio (None, 64, 64, 64, 1 0           decoder_stage4b_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "final_conv (Conv3D)             (None, 64, 64, 64, 2 866         decoder_stage4b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Activation)            (None, 64, 64, 64, 2 0           final_conv[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 71,232,674\n",
      "Trainable params: 71,228,642\n",
      "Non-trainable params: 4,032\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "\n",
    "model = sm.Unet(BACKBONE, classes=n_classes, \n",
    "                input_shape=(patch_size, patch_size, patch_size, channels), # 64，64，64，3\n",
    "                encoder_weights=encoder_weights,  # encoder initialized with imagenet\n",
    "                activation=AKTIV)\n",
    "\n",
    "model.compile(optimizer = optim, loss=total_loss, metrics=metrics)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-28 23:51:32.633107: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-04-28 23:51:32.669232: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3000000000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-28 23:51:37.518206: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-04-28 23:51:45.341903: W tensorflow/stream_executor/gpu/asm_compiler.cc:98] *** WARNING *** You are using ptxas 9.0.176, which is older than 9.2.88. ptxas 9.x before 9.2.88 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You do not need to update to CUDA 9.2.88; cherry-picking the ptxas binary is sufficient.\n",
      "2022-04-28 23:51:45.435143: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/12 [=>............................] - ETA: 3:12 - loss: 0.8438 - iou_score: 0.2507 - f1-score: 0.3873"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-28 23:51:50.475186: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
      "2022-04-28 23:51:50.475229: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n",
      "2022-04-28 23:51:50.476489: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1415] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_INSUFFICIENT_PRIVILEGES\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2/12 [====>.........................] - ETA: 7s - loss: 0.8418 - iou_score: 0.2539 - f1-score: 0.3904  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-28 23:51:51.105539: I tensorflow/core/profiler/lib/profiler_session.cc:71] Profiler session collecting data.\n",
      "2022-04-28 23:51:51.120650: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:228]  GpuTracer has collected 0 callback api events and 0 activity events. \n",
      "2022-04-28 23:51:51.124340: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n",
      "2022-04-28 23:51:51.205137: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: ./transfer3D/tensorBoard/train/plugins/profile/2022_04_28_23_51_51\n",
      "2022-04-28 23:51:51.206016: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for trace.json.gz to ./transfer3D/tensorBoard/train/plugins/profile/2022_04_28_23_51_51/gv016.cluster.trace.json.gz\n",
      "2022-04-28 23:51:51.241334: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: ./transfer3D/tensorBoard/train/plugins/profile/2022_04_28_23_51_51\n",
      "2022-04-28 23:51:51.247150: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for memory_profile.json.gz to ./transfer3D/tensorBoard/train/plugins/profile/2022_04_28_23_51_51/gv016.cluster.memory_profile.json.gz\n",
      "2022-04-28 23:51:51.247982: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: ./transfer3D/tensorBoard/train/plugins/profile/2022_04_28_23_51_51Dumped tool data for xplane.pb to ./transfer3D/tensorBoard/train/plugins/profile/2022_04_28_23_51_51/gv016.cluster.xplane.pb\n",
      "Dumped tool data for overview_page.pb to ./transfer3D/tensorBoard/train/plugins/profile/2022_04_28_23_51_51/gv016.cluster.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to ./transfer3D/tensorBoard/train/plugins/profile/2022_04_28_23_51_51/gv016.cluster.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to ./transfer3D/tensorBoard/train/plugins/profile/2022_04_28_23_51_51/gv016.cluster.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to ./transfer3D/tensorBoard/train/plugins/profile/2022_04_28_23_51_51/gv016.cluster.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 6/12 [==============>...............] - ETA: 4s - loss: 0.8361 - iou_score: 0.2730 - f1-score: 0.4080WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2452s vs `on_train_batch_end` time: 0.3608s). Check your callbacks.\n",
      "12/12 [==============================] - 27s 854ms/step - loss: 0.8280 - iou_score: 0.2981 - f1-score: 0.4284 - val_loss: 0.7984 - val_iou_score: 0.4116 - val_f1-score: 0.5000\n",
      "Epoch 2/500\n",
      "12/12 [==============================] - 8s 706ms/step - loss: 0.7865 - iou_score: 0.4127 - f1-score: 0.4994 - val_loss: 0.7940 - val_iou_score: 0.4314 - val_f1-score: 0.4753\n",
      "Epoch 3/500\n",
      "12/12 [==============================] - 8s 704ms/step - loss: 0.7772 - iou_score: 0.4292 - f1-score: 0.4803 - val_loss: 0.8006 - val_iou_score: 0.4313 - val_f1-score: 0.4748\n",
      "Epoch 4/500\n",
      "12/12 [==============================] - 8s 708ms/step - loss: 0.7733 - iou_score: 0.4310 - f1-score: 0.4720 - val_loss: 0.7984 - val_iou_score: 0.4114 - val_f1-score: 0.5000\n",
      "Epoch 5/500\n",
      "12/12 [==============================] - 8s 707ms/step - loss: 0.7710 - iou_score: 0.4315 - f1-score: 0.4687 - val_loss: 0.7886 - val_iou_score: 0.4315 - val_f1-score: 0.4728\n",
      "Epoch 6/500\n",
      "12/12 [==============================] - 8s 709ms/step - loss: 0.7713 - iou_score: 0.4338 - f1-score: 0.4742 - val_loss: 0.7806 - val_iou_score: 0.4311 - val_f1-score: 0.4681\n",
      "Epoch 7/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7700 - iou_score: 0.4352 - f1-score: 0.4759 - val_loss: 0.7781 - val_iou_score: 0.4309 - val_f1-score: 0.4674\n",
      "Epoch 8/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7701 - iou_score: 0.4343 - f1-score: 0.4751 - val_loss: 0.7748 - val_iou_score: 0.4321 - val_f1-score: 0.4700\n",
      "Epoch 9/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7707 - iou_score: 0.4343 - f1-score: 0.4766 - val_loss: 0.7739 - val_iou_score: 0.4313 - val_f1-score: 0.4684\n",
      "Epoch 10/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7696 - iou_score: 0.4370 - f1-score: 0.4809 - val_loss: 0.7726 - val_iou_score: 0.4341 - val_f1-score: 0.4755\n",
      "Epoch 11/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7695 - iou_score: 0.4350 - f1-score: 0.4766 - val_loss: 0.7730 - val_iou_score: 0.4332 - val_f1-score: 0.4738\n",
      "Epoch 12/500\n",
      "12/12 [==============================] - 8s 714ms/step - loss: 0.7693 - iou_score: 0.4390 - f1-score: 0.4858 - val_loss: 0.7719 - val_iou_score: 0.4327 - val_f1-score: 0.4706\n",
      "Epoch 13/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7692 - iou_score: 0.4372 - f1-score: 0.4806 - val_loss: 0.7721 - val_iou_score: 0.4336 - val_f1-score: 0.4738\n",
      "Epoch 14/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7705 - iou_score: 0.4369 - f1-score: 0.4882 - val_loss: 0.7721 - val_iou_score: 0.4302 - val_f1-score: 0.4637\n",
      "Epoch 15/500\n",
      "12/12 [==============================] - 8s 714ms/step - loss: 0.7701 - iou_score: 0.4333 - f1-score: 0.4724 - val_loss: 0.7720 - val_iou_score: 0.4316 - val_f1-score: 0.4678\n",
      "Epoch 16/500\n",
      "12/12 [==============================] - 8s 714ms/step - loss: 0.7690 - iou_score: 0.4387 - f1-score: 0.4862 - val_loss: 0.7718 - val_iou_score: 0.4376 - val_f1-score: 0.4845\n",
      "Epoch 17/500\n",
      "12/12 [==============================] - 8s 715ms/step - loss: 0.7694 - iou_score: 0.4367 - f1-score: 0.4826 - val_loss: 0.7736 - val_iou_score: 0.4363 - val_f1-score: 0.4827\n",
      "Epoch 18/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7697 - iou_score: 0.4379 - f1-score: 0.4820 - val_loss: 0.7717 - val_iou_score: 0.4350 - val_f1-score: 0.4761\n",
      "Epoch 19/500\n",
      "12/12 [==============================] - 8s 714ms/step - loss: 0.7694 - iou_score: 0.4374 - f1-score: 0.4831 - val_loss: 0.7725 - val_iou_score: 0.4343 - val_f1-score: 0.4746\n",
      "Epoch 20/500\n",
      "12/12 [==============================] - 8s 714ms/step - loss: 0.7703 - iou_score: 0.4352 - f1-score: 0.4773 - val_loss: 0.7755 - val_iou_score: 0.4377 - val_f1-score: 0.4856\n",
      "Epoch 21/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7695 - iou_score: 0.4360 - f1-score: 0.4772 - val_loss: 0.7738 - val_iou_score: 0.4363 - val_f1-score: 0.4801\n",
      "Epoch 22/500\n",
      "12/12 [==============================] - 8s 714ms/step - loss: 0.7683 - iou_score: 0.4429 - f1-score: 0.4944 - val_loss: 0.7732 - val_iou_score: 0.4343 - val_f1-score: 0.4746\n",
      "Epoch 23/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7693 - iou_score: 0.4362 - f1-score: 0.4784 - val_loss: 0.7736 - val_iou_score: 0.4360 - val_f1-score: 0.4791\n",
      "Epoch 24/500\n",
      "12/12 [==============================] - 8s 714ms/step - loss: 0.7691 - iou_score: 0.4387 - f1-score: 0.4847 - val_loss: 0.7718 - val_iou_score: 0.4359 - val_f1-score: 0.4783\n",
      "Epoch 25/500\n",
      "12/12 [==============================] - 8s 714ms/step - loss: 0.7682 - iou_score: 0.4426 - f1-score: 0.4910 - val_loss: 0.7733 - val_iou_score: 0.4364 - val_f1-score: 0.4805\n",
      "Epoch 26/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7695 - iou_score: 0.4361 - f1-score: 0.4795 - val_loss: 0.7712 - val_iou_score: 0.4385 - val_f1-score: 0.4864\n",
      "Epoch 27/500\n",
      "12/12 [==============================] - 9s 716ms/step - loss: 0.7695 - iou_score: 0.4369 - f1-score: 0.4796 - val_loss: 0.7745 - val_iou_score: 0.4379 - val_f1-score: 0.4930\n",
      "Epoch 28/500\n",
      "12/12 [==============================] - 8s 714ms/step - loss: 0.7693 - iou_score: 0.4380 - f1-score: 0.4833 - val_loss: 0.7722 - val_iou_score: 0.4386 - val_f1-score: 0.4877\n",
      "Epoch 29/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7693 - iou_score: 0.4382 - f1-score: 0.4840 - val_loss: 0.7718 - val_iou_score: 0.4357 - val_f1-score: 0.4782\n",
      "Epoch 30/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7693 - iou_score: 0.4355 - f1-score: 0.4752 - val_loss: 0.7748 - val_iou_score: 0.4376 - val_f1-score: 0.4941\n",
      "Epoch 31/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7693 - iou_score: 0.4398 - f1-score: 0.4886 - val_loss: 0.7700 - val_iou_score: 0.4343 - val_f1-score: 0.4738\n",
      "Epoch 32/500\n",
      "12/12 [==============================] - 8s 715ms/step - loss: 0.7686 - iou_score: 0.4385 - f1-score: 0.4839 - val_loss: 0.7752 - val_iou_score: 0.4365 - val_f1-score: 0.4965\n",
      "Epoch 33/500\n",
      "12/12 [==============================] - 8s 714ms/step - loss: 0.7685 - iou_score: 0.4389 - f1-score: 0.4835 - val_loss: 0.7702 - val_iou_score: 0.4368 - val_f1-score: 0.4805\n",
      "Epoch 34/500\n",
      "12/12 [==============================] - 8s 714ms/step - loss: 0.7688 - iou_score: 0.4372 - f1-score: 0.4806 - val_loss: 0.7708 - val_iou_score: 0.4389 - val_f1-score: 0.4873\n",
      "Epoch 35/500\n",
      "12/12 [==============================] - 8s 714ms/step - loss: 0.7690 - iou_score: 0.4405 - f1-score: 0.4888 - val_loss: 0.7707 - val_iou_score: 0.4367 - val_f1-score: 0.4805\n",
      "Epoch 36/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7683 - iou_score: 0.4394 - f1-score: 0.4840 - val_loss: 0.7916 - val_iou_score: 0.3970 - val_f1-score: 0.4939\n",
      "Epoch 37/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7686 - iou_score: 0.4391 - f1-score: 0.4848 - val_loss: 0.7729 - val_iou_score: 0.4371 - val_f1-score: 0.4939\n",
      "Epoch 38/500\n",
      "12/12 [==============================] - 8s 715ms/step - loss: 0.7692 - iou_score: 0.4371 - f1-score: 0.4798 - val_loss: 0.7718 - val_iou_score: 0.4387 - val_f1-score: 0.4908\n",
      "Epoch 39/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7687 - iou_score: 0.4429 - f1-score: 0.4925 - val_loss: 0.7719 - val_iou_score: 0.4370 - val_f1-score: 0.4841\n",
      "Epoch 40/500\n",
      "12/12 [==============================] - 8s 714ms/step - loss: 0.7691 - iou_score: 0.4359 - f1-score: 0.4760 - val_loss: 0.7861 - val_iou_score: 0.4110 - val_f1-score: 0.4999\n",
      "Epoch 41/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7689 - iou_score: 0.4371 - f1-score: 0.4800 - val_loss: 0.7722 - val_iou_score: 0.4378 - val_f1-score: 0.4908\n",
      "Epoch 42/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7679 - iou_score: 0.4423 - f1-score: 0.4915 - val_loss: 0.7708 - val_iou_score: 0.4352 - val_f1-score: 0.4770\n",
      "Epoch 43/500\n",
      "12/12 [==============================] - 9s 716ms/step - loss: 0.7677 - iou_score: 0.4404 - f1-score: 0.4870 - val_loss: 0.7698 - val_iou_score: 0.4337 - val_f1-score: 0.4719\n",
      "Epoch 44/500\n",
      "12/12 [==============================] - 9s 716ms/step - loss: 0.7676 - iou_score: 0.4414 - f1-score: 0.4882 - val_loss: 0.7792 - val_iou_score: 0.4249 - val_f1-score: 0.5020\n",
      "Epoch 45/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7688 - iou_score: 0.4386 - f1-score: 0.4818 - val_loss: 0.7698 - val_iou_score: 0.4367 - val_f1-score: 0.4797\n",
      "Epoch 46/500\n",
      "12/12 [==============================] - 8s 714ms/step - loss: 0.7681 - iou_score: 0.4416 - f1-score: 0.4879 - val_loss: 0.7724 - val_iou_score: 0.4374 - val_f1-score: 0.4940\n",
      "Epoch 47/500\n",
      "12/12 [==============================] - 8s 714ms/step - loss: 0.7685 - iou_score: 0.4398 - f1-score: 0.4855 - val_loss: 0.7699 - val_iou_score: 0.4377 - val_f1-score: 0.4830\n",
      "Epoch 48/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7680 - iou_score: 0.4405 - f1-score: 0.4861 - val_loss: 0.7748 - val_iou_score: 0.4338 - val_f1-score: 0.4976\n",
      "Epoch 49/500\n",
      "12/12 [==============================] - 8s 714ms/step - loss: 0.7675 - iou_score: 0.4419 - f1-score: 0.4884 - val_loss: 0.7699 - val_iou_score: 0.4321 - val_f1-score: 0.4679\n",
      "Epoch 50/500\n",
      "12/12 [==============================] - 8s 715ms/step - loss: 0.7686 - iou_score: 0.4406 - f1-score: 0.4860 - val_loss: 0.7764 - val_iou_score: 0.4304 - val_f1-score: 0.5001\n",
      "Epoch 51/500\n",
      "12/12 [==============================] - 8s 715ms/step - loss: 0.7685 - iou_score: 0.4389 - f1-score: 0.4830 - val_loss: 0.7960 - val_iou_score: 0.3997 - val_f1-score: 0.4955\n",
      "Epoch 52/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7686 - iou_score: 0.4381 - f1-score: 0.4804 - val_loss: 0.7704 - val_iou_score: 0.4317 - val_f1-score: 0.4669\n",
      "Epoch 53/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7682 - iou_score: 0.4398 - f1-score: 0.4833 - val_loss: 0.7721 - val_iou_score: 0.4369 - val_f1-score: 0.4859\n",
      "Epoch 54/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7677 - iou_score: 0.4420 - f1-score: 0.4895 - val_loss: 0.7702 - val_iou_score: 0.4328 - val_f1-score: 0.4702\n",
      "Epoch 55/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7690 - iou_score: 0.4367 - f1-score: 0.4785 - val_loss: 0.8663 - val_iou_score: 0.3675 - val_f1-score: 0.4777\n",
      "Epoch 56/500\n",
      "12/12 [==============================] - 8s 715ms/step - loss: 0.7696 - iou_score: 0.4392 - f1-score: 0.4863 - val_loss: 0.7718 - val_iou_score: 0.4306 - val_f1-score: 0.4641\n",
      "Epoch 57/500\n",
      "12/12 [==============================] - 8s 714ms/step - loss: 0.7686 - iou_score: 0.4387 - f1-score: 0.4820 - val_loss: 0.7725 - val_iou_score: 0.4304 - val_f1-score: 0.4640\n",
      "Epoch 58/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7671 - iou_score: 0.4453 - f1-score: 0.4958 - val_loss: 0.7714 - val_iou_score: 0.4307 - val_f1-score: 0.4649\n",
      "Epoch 59/500\n",
      "12/12 [==============================] - 8s 714ms/step - loss: 0.7659 - iou_score: 0.4480 - f1-score: 0.5010 - val_loss: 0.7706 - val_iou_score: 0.4304 - val_f1-score: 0.4638\n",
      "Epoch 60/500\n",
      "12/12 [==============================] - 9s 715ms/step - loss: 0.7669 - iou_score: 0.4434 - f1-score: 0.4918 - val_loss: 0.7701 - val_iou_score: 0.4329 - val_f1-score: 0.4701\n",
      "Epoch 61/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7676 - iou_score: 0.4404 - f1-score: 0.4852 - val_loss: 0.7702 - val_iou_score: 0.4304 - val_f1-score: 0.4637\n",
      "Epoch 62/500\n",
      "12/12 [==============================] - 8s 714ms/step - loss: 0.7670 - iou_score: 0.4435 - f1-score: 0.4912 - val_loss: 0.7701 - val_iou_score: 0.4308 - val_f1-score: 0.4647\n",
      "Epoch 63/500\n",
      "12/12 [==============================] - 8s 714ms/step - loss: 0.7676 - iou_score: 0.4422 - f1-score: 0.4884 - val_loss: 0.7701 - val_iou_score: 0.4352 - val_f1-score: 0.4760\n",
      "Epoch 64/500\n",
      "12/12 [==============================] - 8s 714ms/step - loss: 0.7657 - iou_score: 0.4472 - f1-score: 0.4988 - val_loss: 0.7701 - val_iou_score: 0.4306 - val_f1-score: 0.4642\n",
      "Epoch 65/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7662 - iou_score: 0.4470 - f1-score: 0.4968 - val_loss: 0.7700 - val_iou_score: 0.4326 - val_f1-score: 0.4690\n",
      "Epoch 66/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7675 - iou_score: 0.4427 - f1-score: 0.4905 - val_loss: 0.7726 - val_iou_score: 0.4380 - val_f1-score: 0.4932\n",
      "Epoch 67/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7673 - iou_score: 0.4443 - f1-score: 0.4931 - val_loss: 0.7710 - val_iou_score: 0.4362 - val_f1-score: 0.4826\n",
      "Epoch 68/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7670 - iou_score: 0.4455 - f1-score: 0.4963 - val_loss: 0.7702 - val_iou_score: 0.4337 - val_f1-score: 0.4727\n",
      "Epoch 69/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7667 - iou_score: 0.4446 - f1-score: 0.4935 - val_loss: 0.7705 - val_iou_score: 0.4305 - val_f1-score: 0.4639\n",
      "Epoch 70/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7661 - iou_score: 0.4466 - f1-score: 0.4962 - val_loss: 0.7702 - val_iou_score: 0.4310 - val_f1-score: 0.4655\n",
      "Epoch 71/500\n",
      "12/12 [==============================] - 8s 714ms/step - loss: 0.7660 - iou_score: 0.4463 - f1-score: 0.4961 - val_loss: 0.7704 - val_iou_score: 0.4306 - val_f1-score: 0.4642\n",
      "Epoch 72/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7666 - iou_score: 0.4451 - f1-score: 0.4926 - val_loss: 0.7704 - val_iou_score: 0.4305 - val_f1-score: 0.4640\n",
      "Epoch 73/500\n",
      "12/12 [==============================] - 8s 714ms/step - loss: 0.7666 - iou_score: 0.4456 - f1-score: 0.4948 - val_loss: 0.7700 - val_iou_score: 0.4310 - val_f1-score: 0.4653\n",
      "Epoch 74/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7671 - iou_score: 0.4435 - f1-score: 0.4911 - val_loss: 0.7703 - val_iou_score: 0.4313 - val_f1-score: 0.4663\n",
      "Epoch 75/500\n",
      "12/12 [==============================] - 8s 714ms/step - loss: 0.7656 - iou_score: 0.4470 - f1-score: 0.4978 - val_loss: 0.7706 - val_iou_score: 0.4310 - val_f1-score: 0.4657\n",
      "Epoch 76/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7658 - iou_score: 0.4469 - f1-score: 0.4967 - val_loss: 0.7704 - val_iou_score: 0.4316 - val_f1-score: 0.4667\n",
      "Epoch 77/500\n",
      "12/12 [==============================] - 8s 714ms/step - loss: 0.7672 - iou_score: 0.4431 - f1-score: 0.4903 - val_loss: 1.0219 - val_iou_score: 0.3548 - val_f1-score: 0.4688\n",
      "Epoch 78/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7669 - iou_score: 0.4444 - f1-score: 0.4917 - val_loss: 0.7710 - val_iou_score: 0.4307 - val_f1-score: 0.4650\n",
      "Epoch 79/500\n",
      "12/12 [==============================] - 9s 715ms/step - loss: 0.7645 - iou_score: 0.4517 - f1-score: 0.5072 - val_loss: 0.7726 - val_iou_score: 0.4356 - val_f1-score: 0.4856\n",
      "Epoch 80/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7652 - iou_score: 0.4486 - f1-score: 0.5003 - val_loss: 0.7708 - val_iou_score: 0.4317 - val_f1-score: 0.4673\n",
      "Epoch 81/500\n",
      "12/12 [==============================] - 8s 714ms/step - loss: 0.7660 - iou_score: 0.4475 - f1-score: 0.4983 - val_loss: 0.7710 - val_iou_score: 0.4303 - val_f1-score: 0.4631\n",
      "Epoch 82/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7651 - iou_score: 0.4495 - f1-score: 0.5011 - val_loss: 0.7701 - val_iou_score: 0.4363 - val_f1-score: 0.4794\n",
      "Epoch 83/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7643 - iou_score: 0.4528 - f1-score: 0.5093 - val_loss: 0.7702 - val_iou_score: 0.4333 - val_f1-score: 0.4708\n",
      "Epoch 84/500\n",
      "12/12 [==============================] - 8s 715ms/step - loss: 0.7666 - iou_score: 0.4434 - f1-score: 0.4900 - val_loss: 0.7699 - val_iou_score: 0.4338 - val_f1-score: 0.4728\n",
      "Epoch 85/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7654 - iou_score: 0.4492 - f1-score: 0.5006 - val_loss: 0.7711 - val_iou_score: 0.4305 - val_f1-score: 0.4639\n",
      "Epoch 86/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7663 - iou_score: 0.4470 - f1-score: 0.4962 - val_loss: 0.7704 - val_iou_score: 0.4346 - val_f1-score: 0.4755\n",
      "Epoch 87/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7673 - iou_score: 0.4413 - f1-score: 0.4848 - val_loss: 0.7721 - val_iou_score: 0.4355 - val_f1-score: 0.4871\n",
      "Epoch 88/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7661 - iou_score: 0.4476 - f1-score: 0.4987 - val_loss: 0.7714 - val_iou_score: 0.4305 - val_f1-score: 0.4638\n",
      "Epoch 89/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7671 - iou_score: 0.4458 - f1-score: 0.4961 - val_loss: 0.7701 - val_iou_score: 0.4341 - val_f1-score: 0.4737\n",
      "Epoch 90/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7671 - iou_score: 0.4451 - f1-score: 0.4938 - val_loss: 0.7704 - val_iou_score: 0.4305 - val_f1-score: 0.4640\n",
      "Epoch 91/500\n",
      "12/12 [==============================] - 8s 714ms/step - loss: 0.7648 - iou_score: 0.4499 - f1-score: 0.5021 - val_loss: 0.7702 - val_iou_score: 0.4316 - val_f1-score: 0.4677\n",
      "Epoch 92/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7661 - iou_score: 0.4477 - f1-score: 0.4984 - val_loss: 0.7704 - val_iou_score: 0.4306 - val_f1-score: 0.4650\n",
      "Epoch 93/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7643 - iou_score: 0.4523 - f1-score: 0.5072 - val_loss: 0.7702 - val_iou_score: 0.4322 - val_f1-score: 0.4695\n",
      "Epoch 94/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7653 - iou_score: 0.4490 - f1-score: 0.5009 - val_loss: 0.7703 - val_iou_score: 0.4323 - val_f1-score: 0.4699\n",
      "Epoch 95/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7673 - iou_score: 0.4450 - f1-score: 0.4951 - val_loss: 0.7759 - val_iou_score: 0.4332 - val_f1-score: 0.4961\n",
      "Epoch 96/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7651 - iou_score: 0.4502 - f1-score: 0.5027 - val_loss: 0.7710 - val_iou_score: 0.4310 - val_f1-score: 0.4671\n",
      "Epoch 97/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7654 - iou_score: 0.4494 - f1-score: 0.5005 - val_loss: 0.7704 - val_iou_score: 0.4307 - val_f1-score: 0.4653\n",
      "Epoch 98/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7656 - iou_score: 0.4483 - f1-score: 0.4994 - val_loss: 0.7715 - val_iou_score: 0.4344 - val_f1-score: 0.4803\n",
      "Epoch 99/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7630 - iou_score: 0.4572 - f1-score: 0.5165 - val_loss: 0.7713 - val_iou_score: 0.4339 - val_f1-score: 0.4731\n",
      "Epoch 100/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7644 - iou_score: 0.4511 - f1-score: 0.5047 - val_loss: 0.7736 - val_iou_score: 0.4369 - val_f1-score: 0.4931\n",
      "Epoch 101/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7657 - iou_score: 0.4481 - f1-score: 0.4987 - val_loss: 0.7703 - val_iou_score: 0.4319 - val_f1-score: 0.4690\n",
      "Epoch 102/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7648 - iou_score: 0.4509 - f1-score: 0.5031 - val_loss: 0.7703 - val_iou_score: 0.4345 - val_f1-score: 0.4769\n",
      "Epoch 103/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7636 - iou_score: 0.4545 - f1-score: 0.5110 - val_loss: 0.7709 - val_iou_score: 0.4310 - val_f1-score: 0.4664\n",
      "Epoch 104/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7639 - iou_score: 0.4541 - f1-score: 0.5114 - val_loss: 0.7706 - val_iou_score: 0.4310 - val_f1-score: 0.4655\n",
      "Epoch 105/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7641 - iou_score: 0.4541 - f1-score: 0.5115 - val_loss: 0.7858 - val_iou_score: 0.4237 - val_f1-score: 0.5020\n",
      "Epoch 106/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7619 - iou_score: 0.4575 - f1-score: 0.5166 - val_loss: 0.8584 - val_iou_score: 0.3773 - val_f1-score: 0.4826\n",
      "Epoch 107/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7645 - iou_score: 0.4508 - f1-score: 0.5029 - val_loss: 0.7705 - val_iou_score: 0.4312 - val_f1-score: 0.4662\n",
      "Epoch 108/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7657 - iou_score: 0.4494 - f1-score: 0.5017 - val_loss: 0.7708 - val_iou_score: 0.4325 - val_f1-score: 0.4693\n",
      "Epoch 109/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7636 - iou_score: 0.4555 - f1-score: 0.5124 - val_loss: 0.7809 - val_iou_score: 0.4249 - val_f1-score: 0.4966\n",
      "Epoch 110/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7663 - iou_score: 0.4463 - f1-score: 0.4955 - val_loss: 0.7712 - val_iou_score: 0.4362 - val_f1-score: 0.4835\n",
      "Epoch 111/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7661 - iou_score: 0.4480 - f1-score: 0.4988 - val_loss: 0.7702 - val_iou_score: 0.4335 - val_f1-score: 0.4732\n",
      "Epoch 112/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7649 - iou_score: 0.4496 - f1-score: 0.5032 - val_loss: 0.8974 - val_iou_score: 0.3591 - val_f1-score: 0.4725\n",
      "Epoch 113/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7646 - iou_score: 0.4523 - f1-score: 0.5070 - val_loss: 0.7727 - val_iou_score: 0.4304 - val_f1-score: 0.4644\n",
      "Epoch 114/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7660 - iou_score: 0.4483 - f1-score: 0.5006 - val_loss: 0.7711 - val_iou_score: 0.4307 - val_f1-score: 0.4648\n",
      "Epoch 115/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7638 - iou_score: 0.4533 - f1-score: 0.5092 - val_loss: 0.7704 - val_iou_score: 0.4322 - val_f1-score: 0.4701\n",
      "Epoch 116/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7633 - iou_score: 0.4558 - f1-score: 0.5144 - val_loss: 0.7707 - val_iou_score: 0.4332 - val_f1-score: 0.4732\n",
      "Epoch 117/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7644 - iou_score: 0.4521 - f1-score: 0.5050 - val_loss: 0.7936 - val_iou_score: 0.4133 - val_f1-score: 0.4983\n",
      "Epoch 118/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7637 - iou_score: 0.4545 - f1-score: 0.5109 - val_loss: 0.7705 - val_iou_score: 0.4334 - val_f1-score: 0.4727\n",
      "Epoch 119/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7662 - iou_score: 0.4493 - f1-score: 0.5051 - val_loss: 0.7703 - val_iou_score: 0.4330 - val_f1-score: 0.4725\n",
      "Epoch 120/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7645 - iou_score: 0.4515 - f1-score: 0.5044 - val_loss: 0.7704 - val_iou_score: 0.4330 - val_f1-score: 0.4729\n",
      "Epoch 121/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7647 - iou_score: 0.4509 - f1-score: 0.5038 - val_loss: 0.7703 - val_iou_score: 0.4329 - val_f1-score: 0.4722\n",
      "Epoch 122/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7621 - iou_score: 0.4584 - f1-score: 0.5176 - val_loss: 0.7710 - val_iou_score: 0.4313 - val_f1-score: 0.4676\n",
      "Epoch 123/500\n",
      "12/12 [==============================] - 8s 714ms/step - loss: 0.7633 - iou_score: 0.4584 - f1-score: 0.5199 - val_loss: 0.7709 - val_iou_score: 0.4316 - val_f1-score: 0.4674\n",
      "Epoch 124/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7634 - iou_score: 0.4545 - f1-score: 0.5110 - val_loss: 0.7725 - val_iou_score: 0.4364 - val_f1-score: 0.4880\n",
      "Epoch 125/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7639 - iou_score: 0.4535 - f1-score: 0.5087 - val_loss: 0.7704 - val_iou_score: 0.4326 - val_f1-score: 0.4715\n",
      "Epoch 126/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7635 - iou_score: 0.4549 - f1-score: 0.5127 - val_loss: 0.7706 - val_iou_score: 0.4314 - val_f1-score: 0.4682\n",
      "Epoch 127/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7645 - iou_score: 0.4514 - f1-score: 0.5048 - val_loss: 0.7706 - val_iou_score: 0.4324 - val_f1-score: 0.4713\n",
      "Epoch 128/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7644 - iou_score: 0.4523 - f1-score: 0.5073 - val_loss: 0.7713 - val_iou_score: 0.4350 - val_f1-score: 0.4826\n",
      "Epoch 129/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7646 - iou_score: 0.4530 - f1-score: 0.5098 - val_loss: 0.7706 - val_iou_score: 0.4327 - val_f1-score: 0.4711\n",
      "Epoch 130/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7622 - iou_score: 0.4587 - f1-score: 0.5188 - val_loss: 0.7708 - val_iou_score: 0.4310 - val_f1-score: 0.4661\n",
      "Epoch 131/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7630 - iou_score: 0.4563 - f1-score: 0.5136 - val_loss: 0.7704 - val_iou_score: 0.4328 - val_f1-score: 0.4722\n",
      "Epoch 132/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7656 - iou_score: 0.4482 - f1-score: 0.4979 - val_loss: 0.7736 - val_iou_score: 0.4327 - val_f1-score: 0.4879\n",
      "Epoch 133/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7625 - iou_score: 0.4597 - f1-score: 0.5218 - val_loss: 0.7710 - val_iou_score: 0.4312 - val_f1-score: 0.4684\n",
      "Epoch 134/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7648 - iou_score: 0.4517 - f1-score: 0.5051 - val_loss: 0.7706 - val_iou_score: 0.4315 - val_f1-score: 0.4689\n",
      "Epoch 135/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7639 - iou_score: 0.4542 - f1-score: 0.5107 - val_loss: 0.7722 - val_iou_score: 0.4308 - val_f1-score: 0.4645\n",
      "Epoch 136/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7632 - iou_score: 0.4567 - f1-score: 0.5150 - val_loss: 0.8211 - val_iou_score: 0.3912 - val_f1-score: 0.4903\n",
      "Epoch 137/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7645 - iou_score: 0.4503 - f1-score: 0.5024 - val_loss: 0.7705 - val_iou_score: 0.4321 - val_f1-score: 0.4688\n",
      "Epoch 138/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7634 - iou_score: 0.4557 - f1-score: 0.5137 - val_loss: 0.7808 - val_iou_score: 0.4261 - val_f1-score: 0.4975\n",
      "Epoch 139/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7623 - iou_score: 0.4587 - f1-score: 0.5166 - val_loss: 0.7706 - val_iou_score: 0.4320 - val_f1-score: 0.4694\n",
      "Epoch 140/500\n",
      "12/12 [==============================] - 8s 709ms/step - loss: 0.7646 - iou_score: 0.4515 - f1-score: 0.5056 - val_loss: 0.7711 - val_iou_score: 0.4319 - val_f1-score: 0.4697\n",
      "Epoch 141/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7639 - iou_score: 0.4535 - f1-score: 0.5087 - val_loss: 0.7708 - val_iou_score: 0.4342 - val_f1-score: 0.4755\n",
      "Epoch 142/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7658 - iou_score: 0.4483 - f1-score: 0.4993 - val_loss: 0.7705 - val_iou_score: 0.4345 - val_f1-score: 0.4762\n",
      "Epoch 143/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7639 - iou_score: 0.4540 - f1-score: 0.5099 - val_loss: 0.7705 - val_iou_score: 0.4350 - val_f1-score: 0.4774\n",
      "Epoch 144/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7639 - iou_score: 0.4534 - f1-score: 0.5095 - val_loss: 0.7707 - val_iou_score: 0.4340 - val_f1-score: 0.4769\n",
      "Epoch 145/500\n",
      "12/12 [==============================] - 8s 709ms/step - loss: 0.7634 - iou_score: 0.4557 - f1-score: 0.5135 - val_loss: 0.7711 - val_iou_score: 0.4341 - val_f1-score: 0.4746\n",
      "Epoch 146/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7620 - iou_score: 0.4582 - f1-score: 0.5165 - val_loss: 0.7704 - val_iou_score: 0.4321 - val_f1-score: 0.4699\n",
      "Epoch 147/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7623 - iou_score: 0.4595 - f1-score: 0.5207 - val_loss: 0.7739 - val_iou_score: 0.4343 - val_f1-score: 0.4863\n",
      "Epoch 148/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7627 - iou_score: 0.4563 - f1-score: 0.5133 - val_loss: 0.7708 - val_iou_score: 0.4322 - val_f1-score: 0.4709\n",
      "Epoch 149/500\n",
      "12/12 [==============================] - 8s 714ms/step - loss: 0.7644 - iou_score: 0.4527 - f1-score: 0.5064 - val_loss: 0.7707 - val_iou_score: 0.4323 - val_f1-score: 0.4709\n",
      "Epoch 150/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7622 - iou_score: 0.4581 - f1-score: 0.5167 - val_loss: 0.7712 - val_iou_score: 0.4312 - val_f1-score: 0.4668\n",
      "Epoch 151/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7644 - iou_score: 0.4528 - f1-score: 0.5091 - val_loss: 0.7711 - val_iou_score: 0.4344 - val_f1-score: 0.4767\n",
      "Epoch 152/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7630 - iou_score: 0.4557 - f1-score: 0.5122 - val_loss: 0.7706 - val_iou_score: 0.4348 - val_f1-score: 0.4784\n",
      "Epoch 153/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7625 - iou_score: 0.4578 - f1-score: 0.5169 - val_loss: 0.7711 - val_iou_score: 0.4323 - val_f1-score: 0.4703\n",
      "Epoch 154/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7620 - iou_score: 0.4608 - f1-score: 0.5233 - val_loss: 0.7714 - val_iou_score: 0.4343 - val_f1-score: 0.4787\n",
      "Epoch 155/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7644 - iou_score: 0.4543 - f1-score: 0.5106 - val_loss: 0.7705 - val_iou_score: 0.4338 - val_f1-score: 0.4754\n",
      "Epoch 156/500\n",
      "12/12 [==============================] - 8s 709ms/step - loss: 0.7624 - iou_score: 0.4582 - f1-score: 0.5167 - val_loss: 0.7707 - val_iou_score: 0.4330 - val_f1-score: 0.4734\n",
      "Epoch 157/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7618 - iou_score: 0.4612 - f1-score: 0.5237 - val_loss: 0.7708 - val_iou_score: 0.4340 - val_f1-score: 0.4762\n",
      "Epoch 158/500\n",
      "12/12 [==============================] - 8s 707ms/step - loss: 0.7635 - iou_score: 0.4547 - f1-score: 0.5114 - val_loss: 0.7709 - val_iou_score: 0.4326 - val_f1-score: 0.4722\n",
      "Epoch 159/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7630 - iou_score: 0.4558 - f1-score: 0.5141 - val_loss: 0.7709 - val_iou_score: 0.4317 - val_f1-score: 0.4697\n",
      "Epoch 160/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7647 - iou_score: 0.4506 - f1-score: 0.5035 - val_loss: 0.7708 - val_iou_score: 0.4336 - val_f1-score: 0.4739\n",
      "Epoch 161/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7620 - iou_score: 0.4602 - f1-score: 0.5223 - val_loss: 0.8002 - val_iou_score: 0.4081 - val_f1-score: 0.4951\n",
      "Epoch 162/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7635 - iou_score: 0.4539 - f1-score: 0.5085 - val_loss: 0.7708 - val_iou_score: 0.4311 - val_f1-score: 0.4672\n",
      "Epoch 163/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7618 - iou_score: 0.4594 - f1-score: 0.5193 - val_loss: 0.7713 - val_iou_score: 0.4336 - val_f1-score: 0.4773\n",
      "Epoch 164/500\n",
      "12/12 [==============================] - 8s 714ms/step - loss: 0.7626 - iou_score: 0.4566 - f1-score: 0.5132 - val_loss: 0.7705 - val_iou_score: 0.4324 - val_f1-score: 0.4713\n",
      "Epoch 165/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7633 - iou_score: 0.4559 - f1-score: 0.5147 - val_loss: 0.7742 - val_iou_score: 0.4342 - val_f1-score: 0.4907\n",
      "Epoch 166/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7625 - iou_score: 0.4572 - f1-score: 0.5145 - val_loss: 0.7709 - val_iou_score: 0.4324 - val_f1-score: 0.4718\n",
      "Epoch 167/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7642 - iou_score: 0.4550 - f1-score: 0.5153 - val_loss: 0.7716 - val_iou_score: 0.4344 - val_f1-score: 0.4756\n",
      "Epoch 168/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7653 - iou_score: 0.4481 - f1-score: 0.4972 - val_loss: 0.7717 - val_iou_score: 0.4342 - val_f1-score: 0.4807\n",
      "Epoch 169/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7644 - iou_score: 0.4535 - f1-score: 0.5129 - val_loss: 0.7779 - val_iou_score: 0.4307 - val_f1-score: 0.4962\n",
      "Epoch 170/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7614 - iou_score: 0.4614 - f1-score: 0.5238 - val_loss: 0.7712 - val_iou_score: 0.4345 - val_f1-score: 0.4794\n",
      "Epoch 171/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7634 - iou_score: 0.4556 - f1-score: 0.5129 - val_loss: 0.7712 - val_iou_score: 0.4337 - val_f1-score: 0.4764\n",
      "Epoch 172/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7626 - iou_score: 0.4576 - f1-score: 0.5178 - val_loss: 0.7707 - val_iou_score: 0.4327 - val_f1-score: 0.4717\n",
      "Epoch 173/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7622 - iou_score: 0.4589 - f1-score: 0.5185 - val_loss: 0.7726 - val_iou_score: 0.4345 - val_f1-score: 0.4847\n",
      "Epoch 174/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7632 - iou_score: 0.4564 - f1-score: 0.5149 - val_loss: 0.7716 - val_iou_score: 0.4329 - val_f1-score: 0.4743\n",
      "Epoch 175/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7609 - iou_score: 0.4630 - f1-score: 0.5254 - val_loss: 0.7716 - val_iou_score: 0.4330 - val_f1-score: 0.4734\n",
      "Epoch 176/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7604 - iou_score: 0.4651 - f1-score: 0.5305 - val_loss: 0.7715 - val_iou_score: 0.4350 - val_f1-score: 0.4798\n",
      "Epoch 177/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7632 - iou_score: 0.4564 - f1-score: 0.5149 - val_loss: 0.7726 - val_iou_score: 0.4369 - val_f1-score: 0.4862\n",
      "Epoch 178/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7607 - iou_score: 0.4634 - f1-score: 0.5272 - val_loss: 0.7713 - val_iou_score: 0.4329 - val_f1-score: 0.4725\n",
      "Epoch 179/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7615 - iou_score: 0.4621 - f1-score: 0.5260 - val_loss: 0.7715 - val_iou_score: 0.4317 - val_f1-score: 0.4685\n",
      "Epoch 180/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7641 - iou_score: 0.4526 - f1-score: 0.5073 - val_loss: 0.7719 - val_iou_score: 0.4324 - val_f1-score: 0.4715\n",
      "Epoch 181/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7620 - iou_score: 0.4604 - f1-score: 0.5232 - val_loss: 0.7708 - val_iou_score: 0.4332 - val_f1-score: 0.4734\n",
      "Epoch 182/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7618 - iou_score: 0.4605 - f1-score: 0.5218 - val_loss: 0.7713 - val_iou_score: 0.4338 - val_f1-score: 0.4771\n",
      "Epoch 183/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7614 - iou_score: 0.4605 - f1-score: 0.5226 - val_loss: 0.7709 - val_iou_score: 0.4325 - val_f1-score: 0.4713\n",
      "Epoch 184/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7598 - iou_score: 0.4663 - f1-score: 0.5330 - val_loss: 0.7717 - val_iou_score: 0.4340 - val_f1-score: 0.4781\n",
      "Epoch 185/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7626 - iou_score: 0.4566 - f1-score: 0.5146 - val_loss: 0.7709 - val_iou_score: 0.4319 - val_f1-score: 0.4700\n",
      "Epoch 186/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7611 - iou_score: 0.4627 - f1-score: 0.5259 - val_loss: 0.7731 - val_iou_score: 0.4319 - val_f1-score: 0.4696\n",
      "Epoch 187/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7614 - iou_score: 0.4603 - f1-score: 0.5218 - val_loss: 0.7776 - val_iou_score: 0.4277 - val_f1-score: 0.4932\n",
      "Epoch 188/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7626 - iou_score: 0.4570 - f1-score: 0.5160 - val_loss: 0.7713 - val_iou_score: 0.4341 - val_f1-score: 0.4765\n",
      "Epoch 189/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7628 - iou_score: 0.4566 - f1-score: 0.5150 - val_loss: 0.7717 - val_iou_score: 0.4343 - val_f1-score: 0.4791\n",
      "Epoch 190/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7613 - iou_score: 0.4608 - f1-score: 0.5226 - val_loss: 0.7711 - val_iou_score: 0.4336 - val_f1-score: 0.4752\n",
      "Epoch 191/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7618 - iou_score: 0.4604 - f1-score: 0.5223 - val_loss: 0.7714 - val_iou_score: 0.4330 - val_f1-score: 0.4727\n",
      "Epoch 192/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7625 - iou_score: 0.4579 - f1-score: 0.5175 - val_loss: 0.7716 - val_iou_score: 0.4325 - val_f1-score: 0.4707\n",
      "Epoch 193/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7635 - iou_score: 0.4548 - f1-score: 0.5132 - val_loss: 0.7716 - val_iou_score: 0.4331 - val_f1-score: 0.4743\n",
      "Epoch 194/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7589 - iou_score: 0.4684 - f1-score: 0.5367 - val_loss: 0.7724 - val_iou_score: 0.4348 - val_f1-score: 0.4840\n",
      "Epoch 195/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7617 - iou_score: 0.4599 - f1-score: 0.5214 - val_loss: 0.7742 - val_iou_score: 0.4351 - val_f1-score: 0.4901\n",
      "Epoch 196/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7594 - iou_score: 0.4659 - f1-score: 0.5314 - val_loss: 0.7715 - val_iou_score: 0.4337 - val_f1-score: 0.4766\n",
      "Epoch 197/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7621 - iou_score: 0.4587 - f1-score: 0.5193 - val_loss: 0.7723 - val_iou_score: 0.4344 - val_f1-score: 0.4836\n",
      "Epoch 198/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7600 - iou_score: 0.4649 - f1-score: 0.5302 - val_loss: 0.7719 - val_iou_score: 0.4345 - val_f1-score: 0.4789\n",
      "Epoch 199/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7618 - iou_score: 0.4603 - f1-score: 0.5216 - val_loss: 0.7723 - val_iou_score: 0.4339 - val_f1-score: 0.4806\n",
      "Epoch 200/500\n",
      "12/12 [==============================] - 8s 709ms/step - loss: 0.7625 - iou_score: 0.4573 - f1-score: 0.5157 - val_loss: 0.7717 - val_iou_score: 0.4343 - val_f1-score: 0.4792\n",
      "Epoch 201/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7613 - iou_score: 0.4608 - f1-score: 0.5244 - val_loss: 0.7717 - val_iou_score: 0.4342 - val_f1-score: 0.4788\n",
      "Epoch 202/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7608 - iou_score: 0.4628 - f1-score: 0.5274 - val_loss: 0.7721 - val_iou_score: 0.4323 - val_f1-score: 0.4703\n",
      "Epoch 203/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7601 - iou_score: 0.4641 - f1-score: 0.5280 - val_loss: 0.7727 - val_iou_score: 0.4347 - val_f1-score: 0.4839\n",
      "Epoch 204/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7617 - iou_score: 0.4607 - f1-score: 0.5236 - val_loss: 0.7715 - val_iou_score: 0.4330 - val_f1-score: 0.4737\n",
      "Epoch 205/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7618 - iou_score: 0.4602 - f1-score: 0.5230 - val_loss: 0.7718 - val_iou_score: 0.4325 - val_f1-score: 0.4720\n",
      "Epoch 206/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7623 - iou_score: 0.4587 - f1-score: 0.5199 - val_loss: 0.7720 - val_iou_score: 0.4337 - val_f1-score: 0.4779\n",
      "Epoch 207/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7623 - iou_score: 0.4579 - f1-score: 0.5178 - val_loss: 0.7724 - val_iou_score: 0.4342 - val_f1-score: 0.4809\n",
      "Epoch 208/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7584 - iou_score: 0.4690 - f1-score: 0.5377 - val_loss: 0.7723 - val_iou_score: 0.4338 - val_f1-score: 0.4770\n",
      "Epoch 209/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7619 - iou_score: 0.4590 - f1-score: 0.5202 - val_loss: 0.7745 - val_iou_score: 0.4340 - val_f1-score: 0.4894\n",
      "Epoch 210/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7603 - iou_score: 0.4638 - f1-score: 0.5283 - val_loss: 0.7726 - val_iou_score: 0.4343 - val_f1-score: 0.4803\n",
      "Epoch 211/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7623 - iou_score: 0.4573 - f1-score: 0.5169 - val_loss: 0.7760 - val_iou_score: 0.4327 - val_f1-score: 0.4931\n",
      "Epoch 212/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7637 - iou_score: 0.4557 - f1-score: 0.5167 - val_loss: 0.7724 - val_iou_score: 0.4348 - val_f1-score: 0.4815\n",
      "Epoch 213/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7600 - iou_score: 0.4655 - f1-score: 0.5323 - val_loss: 0.7724 - val_iou_score: 0.4343 - val_f1-score: 0.4814\n",
      "Epoch 214/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7605 - iou_score: 0.4628 - f1-score: 0.5265 - val_loss: 0.7715 - val_iou_score: 0.4332 - val_f1-score: 0.4734\n",
      "Epoch 215/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7623 - iou_score: 0.4584 - f1-score: 0.5195 - val_loss: 0.7719 - val_iou_score: 0.4330 - val_f1-score: 0.4737\n",
      "Epoch 216/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7603 - iou_score: 0.4642 - f1-score: 0.5301 - val_loss: 0.7725 - val_iou_score: 0.4343 - val_f1-score: 0.4812\n",
      "Epoch 217/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7605 - iou_score: 0.4651 - f1-score: 0.5308 - val_loss: 0.7717 - val_iou_score: 0.4324 - val_f1-score: 0.4708\n",
      "Epoch 218/500\n",
      "12/12 [==============================] - 8s 709ms/step - loss: 0.7589 - iou_score: 0.4675 - f1-score: 0.5353 - val_loss: 0.7728 - val_iou_score: 0.4342 - val_f1-score: 0.4773\n",
      "Epoch 219/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7625 - iou_score: 0.4563 - f1-score: 0.5149 - val_loss: 0.7719 - val_iou_score: 0.4341 - val_f1-score: 0.4772\n",
      "Epoch 220/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7603 - iou_score: 0.4646 - f1-score: 0.5307 - val_loss: 0.7893 - val_iou_score: 0.4214 - val_f1-score: 0.5000\n",
      "Epoch 221/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7602 - iou_score: 0.4621 - f1-score: 0.5254 - val_loss: 0.7720 - val_iou_score: 0.4333 - val_f1-score: 0.4755\n",
      "Epoch 222/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7595 - iou_score: 0.4666 - f1-score: 0.5333 - val_loss: 0.7741 - val_iou_score: 0.4339 - val_f1-score: 0.4775\n",
      "Epoch 223/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7586 - iou_score: 0.4668 - f1-score: 0.5332 - val_loss: 0.7721 - val_iou_score: 0.4328 - val_f1-score: 0.4731\n",
      "Epoch 224/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7598 - iou_score: 0.4639 - f1-score: 0.5290 - val_loss: 0.7738 - val_iou_score: 0.4324 - val_f1-score: 0.4718\n",
      "Epoch 225/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7602 - iou_score: 0.4632 - f1-score: 0.5276 - val_loss: 0.7722 - val_iou_score: 0.4334 - val_f1-score: 0.4765\n",
      "Epoch 226/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7584 - iou_score: 0.4692 - f1-score: 0.5389 - val_loss: 0.7733 - val_iou_score: 0.4327 - val_f1-score: 0.4718\n",
      "Epoch 227/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7579 - iou_score: 0.4684 - f1-score: 0.5362 - val_loss: 0.7723 - val_iou_score: 0.4327 - val_f1-score: 0.4738\n",
      "Epoch 228/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7631 - iou_score: 0.4553 - f1-score: 0.5140 - val_loss: 0.7729 - val_iou_score: 0.4343 - val_f1-score: 0.4810\n",
      "Epoch 229/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7610 - iou_score: 0.4614 - f1-score: 0.5244 - val_loss: 0.7727 - val_iou_score: 0.4327 - val_f1-score: 0.4727\n",
      "Epoch 230/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7592 - iou_score: 0.4668 - f1-score: 0.5351 - val_loss: 0.7727 - val_iou_score: 0.4336 - val_f1-score: 0.4777\n",
      "Epoch 231/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7587 - iou_score: 0.4662 - f1-score: 0.5325 - val_loss: 0.7723 - val_iou_score: 0.4338 - val_f1-score: 0.4774\n",
      "Epoch 232/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7586 - iou_score: 0.4674 - f1-score: 0.5348 - val_loss: 0.7728 - val_iou_score: 0.4342 - val_f1-score: 0.4821\n",
      "Epoch 233/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7593 - iou_score: 0.4663 - f1-score: 0.5341 - val_loss: 0.7786 - val_iou_score: 0.4315 - val_f1-score: 0.4966\n",
      "Epoch 234/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7603 - iou_score: 0.4638 - f1-score: 0.5294 - val_loss: 0.7734 - val_iou_score: 0.4351 - val_f1-score: 0.4858\n",
      "Epoch 235/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7630 - iou_score: 0.4566 - f1-score: 0.5173 - val_loss: 0.7746 - val_iou_score: 0.4344 - val_f1-score: 0.4892\n",
      "Epoch 236/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7600 - iou_score: 0.4654 - f1-score: 0.5331 - val_loss: 0.7729 - val_iou_score: 0.4336 - val_f1-score: 0.4766\n",
      "Epoch 237/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7604 - iou_score: 0.4627 - f1-score: 0.5273 - val_loss: 0.7728 - val_iou_score: 0.4337 - val_f1-score: 0.4771\n",
      "Epoch 238/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7582 - iou_score: 0.4678 - f1-score: 0.5359 - val_loss: 0.7722 - val_iou_score: 0.4332 - val_f1-score: 0.4750\n",
      "Epoch 239/500\n",
      "12/12 [==============================] - 8s 709ms/step - loss: 0.7598 - iou_score: 0.4641 - f1-score: 0.5290 - val_loss: 0.7731 - val_iou_score: 0.4335 - val_f1-score: 0.4761\n",
      "Epoch 240/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7579 - iou_score: 0.4687 - f1-score: 0.5381 - val_loss: 0.7730 - val_iou_score: 0.4342 - val_f1-score: 0.4822\n",
      "Epoch 241/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7572 - iou_score: 0.4717 - f1-score: 0.5434 - val_loss: 0.7734 - val_iou_score: 0.4334 - val_f1-score: 0.4759\n",
      "Epoch 242/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7581 - iou_score: 0.4674 - f1-score: 0.5344 - val_loss: 0.7722 - val_iou_score: 0.4335 - val_f1-score: 0.4771\n",
      "Epoch 243/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7593 - iou_score: 0.4665 - f1-score: 0.5345 - val_loss: 0.7740 - val_iou_score: 0.4335 - val_f1-score: 0.4759\n",
      "Epoch 244/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7605 - iou_score: 0.4615 - f1-score: 0.5254 - val_loss: 0.7727 - val_iou_score: 0.4341 - val_f1-score: 0.4802\n",
      "Epoch 245/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7565 - iou_score: 0.4732 - f1-score: 0.5459 - val_loss: 0.7743 - val_iou_score: 0.4346 - val_f1-score: 0.4878\n",
      "Epoch 246/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7600 - iou_score: 0.4664 - f1-score: 0.5357 - val_loss: 0.7734 - val_iou_score: 0.4343 - val_f1-score: 0.4788\n",
      "Epoch 247/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7584 - iou_score: 0.4672 - f1-score: 0.5351 - val_loss: 0.7733 - val_iou_score: 0.4351 - val_f1-score: 0.4851\n",
      "Epoch 248/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7608 - iou_score: 0.4615 - f1-score: 0.5261 - val_loss: 0.7739 - val_iou_score: 0.4349 - val_f1-score: 0.4828\n",
      "Epoch 249/500\n",
      "12/12 [==============================] - 8s 709ms/step - loss: 0.7570 - iou_score: 0.4715 - f1-score: 0.5432 - val_loss: 0.7733 - val_iou_score: 0.4336 - val_f1-score: 0.4780\n",
      "Epoch 250/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7586 - iou_score: 0.4671 - f1-score: 0.5352 - val_loss: 0.7730 - val_iou_score: 0.4338 - val_f1-score: 0.4783\n",
      "Epoch 251/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7575 - iou_score: 0.4708 - f1-score: 0.5419 - val_loss: 0.7744 - val_iou_score: 0.4352 - val_f1-score: 0.4871\n",
      "Epoch 252/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7599 - iou_score: 0.4653 - f1-score: 0.5332 - val_loss: 0.7725 - val_iou_score: 0.4329 - val_f1-score: 0.4747\n",
      "Epoch 253/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7575 - iou_score: 0.4703 - f1-score: 0.5416 - val_loss: 0.7735 - val_iou_score: 0.4334 - val_f1-score: 0.4763\n",
      "Epoch 254/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7568 - iou_score: 0.4715 - f1-score: 0.5424 - val_loss: 0.7765 - val_iou_score: 0.4337 - val_f1-score: 0.4928\n",
      "Epoch 255/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7604 - iou_score: 0.4632 - f1-score: 0.5295 - val_loss: 0.7746 - val_iou_score: 0.4342 - val_f1-score: 0.4788\n",
      "Epoch 256/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7586 - iou_score: 0.4664 - f1-score: 0.5329 - val_loss: 0.7736 - val_iou_score: 0.4340 - val_f1-score: 0.4835\n",
      "Epoch 257/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7580 - iou_score: 0.4695 - f1-score: 0.5403 - val_loss: 0.7735 - val_iou_score: 0.4331 - val_f1-score: 0.4746\n",
      "Epoch 258/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7579 - iou_score: 0.4686 - f1-score: 0.5370 - val_loss: 0.7740 - val_iou_score: 0.4330 - val_f1-score: 0.4743\n",
      "Epoch 259/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7590 - iou_score: 0.4656 - f1-score: 0.5325 - val_loss: 0.7744 - val_iou_score: 0.4342 - val_f1-score: 0.4821\n",
      "Epoch 260/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7596 - iou_score: 0.4653 - f1-score: 0.5320 - val_loss: 0.7744 - val_iou_score: 0.4345 - val_f1-score: 0.4857\n",
      "Epoch 261/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7587 - iou_score: 0.4675 - f1-score: 0.5362 - val_loss: 0.7738 - val_iou_score: 0.4340 - val_f1-score: 0.4831\n",
      "Epoch 262/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7558 - iou_score: 0.4744 - f1-score: 0.5484 - val_loss: 0.7750 - val_iou_score: 0.4344 - val_f1-score: 0.4891\n",
      "Epoch 263/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7570 - iou_score: 0.4718 - f1-score: 0.5443 - val_loss: 0.7761 - val_iou_score: 0.4327 - val_f1-score: 0.4920\n",
      "Epoch 264/500\n",
      "12/12 [==============================] - 8s 709ms/step - loss: 0.7583 - iou_score: 0.4681 - f1-score: 0.5360 - val_loss: 0.7741 - val_iou_score: 0.4344 - val_f1-score: 0.4857\n",
      "Epoch 265/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7568 - iou_score: 0.4727 - f1-score: 0.5464 - val_loss: 0.7740 - val_iou_score: 0.4340 - val_f1-score: 0.4800\n",
      "Epoch 266/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7556 - iou_score: 0.4751 - f1-score: 0.5496 - val_loss: 0.7751 - val_iou_score: 0.4341 - val_f1-score: 0.4841\n",
      "Epoch 267/500\n",
      "12/12 [==============================] - 8s 714ms/step - loss: 0.7574 - iou_score: 0.4709 - f1-score: 0.5417 - val_loss: 0.7742 - val_iou_score: 0.4342 - val_f1-score: 0.4835\n",
      "Epoch 268/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7562 - iou_score: 0.4739 - f1-score: 0.5480 - val_loss: 0.7746 - val_iou_score: 0.4337 - val_f1-score: 0.4768\n",
      "Epoch 269/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7560 - iou_score: 0.4740 - f1-score: 0.5463 - val_loss: 0.7748 - val_iou_score: 0.4342 - val_f1-score: 0.4860\n",
      "Epoch 270/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7572 - iou_score: 0.4726 - f1-score: 0.5459 - val_loss: 0.7772 - val_iou_score: 0.4323 - val_f1-score: 0.4928\n",
      "Epoch 271/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7587 - iou_score: 0.4689 - f1-score: 0.5403 - val_loss: 0.7737 - val_iou_score: 0.4344 - val_f1-score: 0.4842\n",
      "Epoch 272/500\n",
      "12/12 [==============================] - 8s 709ms/step - loss: 0.7590 - iou_score: 0.4676 - f1-score: 0.5385 - val_loss: 0.7745 - val_iou_score: 0.4346 - val_f1-score: 0.4872\n",
      "Epoch 273/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7593 - iou_score: 0.4666 - f1-score: 0.5362 - val_loss: 0.7746 - val_iou_score: 0.4341 - val_f1-score: 0.4794\n",
      "Epoch 274/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7590 - iou_score: 0.4668 - f1-score: 0.5355 - val_loss: 0.7738 - val_iou_score: 0.4342 - val_f1-score: 0.4793\n",
      "Epoch 275/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7572 - iou_score: 0.4721 - f1-score: 0.5452 - val_loss: 0.7738 - val_iou_score: 0.4336 - val_f1-score: 0.4767\n",
      "Epoch 276/500\n",
      "12/12 [==============================] - 8s 709ms/step - loss: 0.7569 - iou_score: 0.4721 - f1-score: 0.5450 - val_loss: 0.7742 - val_iou_score: 0.4336 - val_f1-score: 0.4783\n",
      "Epoch 277/500\n",
      "12/12 [==============================] - 8s 709ms/step - loss: 0.7551 - iou_score: 0.4758 - f1-score: 0.5516 - val_loss: 0.7739 - val_iou_score: 0.4340 - val_f1-score: 0.4847\n",
      "Epoch 278/500\n",
      "12/12 [==============================] - 8s 709ms/step - loss: 0.7571 - iou_score: 0.4721 - f1-score: 0.5446 - val_loss: 0.7745 - val_iou_score: 0.4335 - val_f1-score: 0.4774\n",
      "Epoch 279/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7566 - iou_score: 0.4734 - f1-score: 0.5473 - val_loss: 0.7744 - val_iou_score: 0.4337 - val_f1-score: 0.4810\n",
      "Epoch 280/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7580 - iou_score: 0.4697 - f1-score: 0.5423 - val_loss: 0.7745 - val_iou_score: 0.4341 - val_f1-score: 0.4821\n",
      "Epoch 281/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7581 - iou_score: 0.4710 - f1-score: 0.5440 - val_loss: 0.7753 - val_iou_score: 0.4346 - val_f1-score: 0.4822\n",
      "Epoch 282/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7568 - iou_score: 0.4728 - f1-score: 0.5467 - val_loss: 0.7752 - val_iou_score: 0.4346 - val_f1-score: 0.4851\n",
      "Epoch 283/500\n",
      "12/12 [==============================] - 8s 709ms/step - loss: 0.7561 - iou_score: 0.4736 - f1-score: 0.5464 - val_loss: 0.7777 - val_iou_score: 0.4347 - val_f1-score: 0.4917\n",
      "Epoch 284/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7577 - iou_score: 0.4697 - f1-score: 0.5411 - val_loss: 0.7748 - val_iou_score: 0.4345 - val_f1-score: 0.4853\n",
      "Epoch 285/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7555 - iou_score: 0.4763 - f1-score: 0.5523 - val_loss: 0.7744 - val_iou_score: 0.4335 - val_f1-score: 0.4845\n",
      "Epoch 286/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7576 - iou_score: 0.4710 - f1-score: 0.5438 - val_loss: 0.7751 - val_iou_score: 0.4341 - val_f1-score: 0.4828\n",
      "Epoch 287/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7528 - iou_score: 0.4824 - f1-score: 0.5623 - val_loss: 0.7772 - val_iou_score: 0.4334 - val_f1-score: 0.4902\n",
      "Epoch 288/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7564 - iou_score: 0.4738 - f1-score: 0.5482 - val_loss: 0.7753 - val_iou_score: 0.4340 - val_f1-score: 0.4847\n",
      "Epoch 289/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7554 - iou_score: 0.4763 - f1-score: 0.5518 - val_loss: 0.7761 - val_iou_score: 0.4333 - val_f1-score: 0.4906\n",
      "Epoch 290/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7560 - iou_score: 0.4748 - f1-score: 0.5513 - val_loss: 0.7755 - val_iou_score: 0.4340 - val_f1-score: 0.4803\n",
      "Epoch 291/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7557 - iou_score: 0.4750 - f1-score: 0.5496 - val_loss: 0.7749 - val_iou_score: 0.4342 - val_f1-score: 0.4817\n",
      "Epoch 292/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7536 - iou_score: 0.4806 - f1-score: 0.5598 - val_loss: 0.7758 - val_iou_score: 0.4341 - val_f1-score: 0.4866\n",
      "Epoch 293/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7546 - iou_score: 0.4782 - f1-score: 0.5562 - val_loss: 0.7754 - val_iou_score: 0.4342 - val_f1-score: 0.4835\n",
      "Epoch 294/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7565 - iou_score: 0.4741 - f1-score: 0.5494 - val_loss: 0.7765 - val_iou_score: 0.4337 - val_f1-score: 0.4912\n",
      "Epoch 295/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7554 - iou_score: 0.4760 - f1-score: 0.5522 - val_loss: 0.7753 - val_iou_score: 0.4342 - val_f1-score: 0.4869\n",
      "Epoch 296/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7569 - iou_score: 0.4731 - f1-score: 0.5484 - val_loss: 0.7760 - val_iou_score: 0.4338 - val_f1-score: 0.4876\n",
      "Epoch 297/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7525 - iou_score: 0.4837 - f1-score: 0.5646 - val_loss: 0.7765 - val_iou_score: 0.4340 - val_f1-score: 0.4795\n",
      "Epoch 298/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7575 - iou_score: 0.4712 - f1-score: 0.5440 - val_loss: 0.7795 - val_iou_score: 0.4307 - val_f1-score: 0.4964\n",
      "Epoch 299/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7562 - iou_score: 0.4744 - f1-score: 0.5489 - val_loss: 0.7757 - val_iou_score: 0.4345 - val_f1-score: 0.4912\n",
      "Epoch 300/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7536 - iou_score: 0.4805 - f1-score: 0.5605 - val_loss: 0.7802 - val_iou_score: 0.4300 - val_f1-score: 0.4962\n",
      "Epoch 301/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7556 - iou_score: 0.4757 - f1-score: 0.5527 - val_loss: 0.7773 - val_iou_score: 0.4327 - val_f1-score: 0.4946\n",
      "Epoch 302/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7560 - iou_score: 0.4756 - f1-score: 0.5524 - val_loss: 0.7761 - val_iou_score: 0.4336 - val_f1-score: 0.4883\n",
      "Epoch 303/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7562 - iou_score: 0.4746 - f1-score: 0.5496 - val_loss: 0.7763 - val_iou_score: 0.4337 - val_f1-score: 0.4872\n",
      "Epoch 304/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7548 - iou_score: 0.4773 - f1-score: 0.5536 - val_loss: 0.7761 - val_iou_score: 0.4342 - val_f1-score: 0.4845\n",
      "Epoch 305/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7572 - iou_score: 0.4740 - f1-score: 0.5500 - val_loss: 0.7770 - val_iou_score: 0.4333 - val_f1-score: 0.4906\n",
      "Epoch 306/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7540 - iou_score: 0.4800 - f1-score: 0.5586 - val_loss: 0.7765 - val_iou_score: 0.4341 - val_f1-score: 0.4870\n",
      "Epoch 307/500\n",
      "12/12 [==============================] - 8s 709ms/step - loss: 0.7546 - iou_score: 0.4783 - f1-score: 0.5563 - val_loss: 0.7768 - val_iou_score: 0.4343 - val_f1-score: 0.4816\n",
      "Epoch 308/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7527 - iou_score: 0.4832 - f1-score: 0.5642 - val_loss: 0.7764 - val_iou_score: 0.4344 - val_f1-score: 0.4851\n",
      "Epoch 309/500\n",
      "12/12 [==============================] - 8s 709ms/step - loss: 0.7541 - iou_score: 0.4796 - f1-score: 0.5585 - val_loss: 0.7768 - val_iou_score: 0.4336 - val_f1-score: 0.4865\n",
      "Epoch 310/500\n",
      "12/12 [==============================] - 8s 708ms/step - loss: 0.7538 - iou_score: 0.4804 - f1-score: 0.5594 - val_loss: 0.7771 - val_iou_score: 0.4341 - val_f1-score: 0.4820\n",
      "Epoch 311/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7513 - iou_score: 0.4863 - f1-score: 0.5691 - val_loss: 0.7776 - val_iou_score: 0.4338 - val_f1-score: 0.4894\n",
      "Epoch 312/500\n",
      "12/12 [==============================] - 8s 709ms/step - loss: 0.7555 - iou_score: 0.4762 - f1-score: 0.5520 - val_loss: 0.7781 - val_iou_score: 0.4336 - val_f1-score: 0.4777\n",
      "Epoch 313/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7529 - iou_score: 0.4820 - f1-score: 0.5621 - val_loss: 0.7763 - val_iou_score: 0.4338 - val_f1-score: 0.4864\n",
      "Epoch 314/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7569 - iou_score: 0.4732 - f1-score: 0.5480 - val_loss: 0.7777 - val_iou_score: 0.4327 - val_f1-score: 0.4922\n",
      "Epoch 315/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7539 - iou_score: 0.4802 - f1-score: 0.5599 - val_loss: 0.7764 - val_iou_score: 0.4334 - val_f1-score: 0.4890\n",
      "Epoch 316/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7533 - iou_score: 0.4823 - f1-score: 0.5636 - val_loss: 0.7774 - val_iou_score: 0.4335 - val_f1-score: 0.4866\n",
      "Epoch 317/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7514 - iou_score: 0.4860 - f1-score: 0.5685 - val_loss: 0.7771 - val_iou_score: 0.4337 - val_f1-score: 0.4855\n",
      "Epoch 318/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7534 - iou_score: 0.4822 - f1-score: 0.5638 - val_loss: 0.7770 - val_iou_score: 0.4342 - val_f1-score: 0.4874\n",
      "Epoch 319/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7535 - iou_score: 0.4813 - f1-score: 0.5605 - val_loss: 0.7760 - val_iou_score: 0.4339 - val_f1-score: 0.4874\n",
      "Epoch 320/500\n",
      "12/12 [==============================] - 8s 709ms/step - loss: 0.7511 - iou_score: 0.4881 - f1-score: 0.5724 - val_loss: 0.7779 - val_iou_score: 0.4331 - val_f1-score: 0.4888\n",
      "Epoch 321/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7516 - iou_score: 0.4856 - f1-score: 0.5677 - val_loss: 0.7759 - val_iou_score: 0.4340 - val_f1-score: 0.4852\n",
      "Epoch 322/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7532 - iou_score: 0.4815 - f1-score: 0.5616 - val_loss: 0.7820 - val_iou_score: 0.4295 - val_f1-score: 0.4968\n",
      "Epoch 323/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7536 - iou_score: 0.4823 - f1-score: 0.5639 - val_loss: 0.7785 - val_iou_score: 0.4329 - val_f1-score: 0.4930\n",
      "Epoch 324/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7502 - iou_score: 0.4886 - f1-score: 0.5724 - val_loss: 0.7774 - val_iou_score: 0.4329 - val_f1-score: 0.4900\n",
      "Epoch 325/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7497 - iou_score: 0.4901 - f1-score: 0.5753 - val_loss: 0.7773 - val_iou_score: 0.4327 - val_f1-score: 0.4887\n",
      "Epoch 326/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7526 - iou_score: 0.4844 - f1-score: 0.5664 - val_loss: 0.7776 - val_iou_score: 0.4336 - val_f1-score: 0.4892\n",
      "Epoch 327/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7550 - iou_score: 0.4792 - f1-score: 0.5593 - val_loss: 0.7797 - val_iou_score: 0.4324 - val_f1-score: 0.4937\n",
      "Epoch 328/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7511 - iou_score: 0.4869 - f1-score: 0.5705 - val_loss: 0.7774 - val_iou_score: 0.4332 - val_f1-score: 0.4855\n",
      "Epoch 329/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7489 - iou_score: 0.4919 - f1-score: 0.5782 - val_loss: 0.7778 - val_iou_score: 0.4340 - val_f1-score: 0.4860\n",
      "Epoch 330/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7548 - iou_score: 0.4787 - f1-score: 0.5570 - val_loss: 0.7809 - val_iou_score: 0.4307 - val_f1-score: 0.4956\n",
      "Epoch 331/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7528 - iou_score: 0.4826 - f1-score: 0.5633 - val_loss: 0.7775 - val_iou_score: 0.4334 - val_f1-score: 0.4890\n",
      "Epoch 332/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7538 - iou_score: 0.4817 - f1-score: 0.5627 - val_loss: 0.7774 - val_iou_score: 0.4339 - val_f1-score: 0.4879\n",
      "Epoch 333/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7520 - iou_score: 0.4861 - f1-score: 0.5692 - val_loss: 0.7775 - val_iou_score: 0.4334 - val_f1-score: 0.4876\n",
      "Epoch 334/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7501 - iou_score: 0.4900 - f1-score: 0.5749 - val_loss: 0.7796 - val_iou_score: 0.4322 - val_f1-score: 0.4927\n",
      "Epoch 335/500\n",
      "12/12 [==============================] - 8s 708ms/step - loss: 0.7547 - iou_score: 0.4793 - f1-score: 0.5573 - val_loss: 0.7777 - val_iou_score: 0.4337 - val_f1-score: 0.4867\n",
      "Epoch 336/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7510 - iou_score: 0.4873 - f1-score: 0.5720 - val_loss: 0.7812 - val_iou_score: 0.4310 - val_f1-score: 0.4951\n",
      "Epoch 337/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7521 - iou_score: 0.4854 - f1-score: 0.5681 - val_loss: 0.7791 - val_iou_score: 0.4339 - val_f1-score: 0.4890\n",
      "Epoch 338/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7512 - iou_score: 0.4872 - f1-score: 0.5705 - val_loss: 0.7795 - val_iou_score: 0.4331 - val_f1-score: 0.4901\n",
      "Epoch 339/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7503 - iou_score: 0.4904 - f1-score: 0.5752 - val_loss: 0.7782 - val_iou_score: 0.4334 - val_f1-score: 0.4906\n",
      "Epoch 340/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7516 - iou_score: 0.4865 - f1-score: 0.5693 - val_loss: 0.7789 - val_iou_score: 0.4330 - val_f1-score: 0.4876\n",
      "Epoch 341/500\n",
      "12/12 [==============================] - 8s 708ms/step - loss: 0.7516 - iou_score: 0.4871 - f1-score: 0.5721 - val_loss: 0.7789 - val_iou_score: 0.4331 - val_f1-score: 0.4883\n",
      "Epoch 342/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7502 - iou_score: 0.4898 - f1-score: 0.5748 - val_loss: 0.7780 - val_iou_score: 0.4336 - val_f1-score: 0.4866\n",
      "Epoch 343/500\n",
      "12/12 [==============================] - 8s 709ms/step - loss: 0.7548 - iou_score: 0.4791 - f1-score: 0.5577 - val_loss: 0.7796 - val_iou_score: 0.4334 - val_f1-score: 0.4880\n",
      "Epoch 344/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7485 - iou_score: 0.4948 - f1-score: 0.5827 - val_loss: 0.7799 - val_iou_score: 0.4341 - val_f1-score: 0.4828\n",
      "Epoch 345/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7524 - iou_score: 0.4850 - f1-score: 0.5671 - val_loss: 0.7814 - val_iou_score: 0.4298 - val_f1-score: 0.4964\n",
      "Epoch 346/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7532 - iou_score: 0.4842 - f1-score: 0.5678 - val_loss: 0.7789 - val_iou_score: 0.4318 - val_f1-score: 0.4916\n",
      "Epoch 347/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7486 - iou_score: 0.4937 - f1-score: 0.5817 - val_loss: 0.7789 - val_iou_score: 0.4332 - val_f1-score: 0.4849\n",
      "Epoch 348/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7518 - iou_score: 0.4862 - f1-score: 0.5689 - val_loss: 0.7810 - val_iou_score: 0.4310 - val_f1-score: 0.4941\n",
      "Epoch 349/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7484 - iou_score: 0.4944 - f1-score: 0.5809 - val_loss: 0.7791 - val_iou_score: 0.4329 - val_f1-score: 0.4905\n",
      "Epoch 350/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7518 - iou_score: 0.4856 - f1-score: 0.5684 - val_loss: 0.7784 - val_iou_score: 0.4331 - val_f1-score: 0.4894\n",
      "Epoch 351/500\n",
      "12/12 [==============================] - 8s 708ms/step - loss: 0.7500 - iou_score: 0.4902 - f1-score: 0.5757 - val_loss: 0.7817 - val_iou_score: 0.4303 - val_f1-score: 0.4954\n",
      "Epoch 352/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7488 - iou_score: 0.4929 - f1-score: 0.5793 - val_loss: 0.7793 - val_iou_score: 0.4331 - val_f1-score: 0.4884\n",
      "Epoch 353/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7497 - iou_score: 0.4913 - f1-score: 0.5780 - val_loss: 0.7796 - val_iou_score: 0.4327 - val_f1-score: 0.4900\n",
      "Epoch 354/500\n",
      "12/12 [==============================] - 8s 709ms/step - loss: 0.7486 - iou_score: 0.4939 - f1-score: 0.5820 - val_loss: 0.7787 - val_iou_score: 0.4332 - val_f1-score: 0.4880\n",
      "Epoch 355/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7481 - iou_score: 0.4948 - f1-score: 0.5837 - val_loss: 0.7795 - val_iou_score: 0.4333 - val_f1-score: 0.4879\n",
      "Epoch 356/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7528 - iou_score: 0.4849 - f1-score: 0.5679 - val_loss: 0.7810 - val_iou_score: 0.4325 - val_f1-score: 0.4904\n",
      "Epoch 357/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7506 - iou_score: 0.4887 - f1-score: 0.5726 - val_loss: 0.7803 - val_iou_score: 0.4319 - val_f1-score: 0.4925\n",
      "Epoch 358/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7517 - iou_score: 0.4877 - f1-score: 0.5730 - val_loss: 0.7803 - val_iou_score: 0.4331 - val_f1-score: 0.4915\n",
      "Epoch 359/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7506 - iou_score: 0.4890 - f1-score: 0.5736 - val_loss: 0.7803 - val_iou_score: 0.4329 - val_f1-score: 0.4904\n",
      "Epoch 360/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7490 - iou_score: 0.4932 - f1-score: 0.5834 - val_loss: 0.7800 - val_iou_score: 0.4311 - val_f1-score: 0.4953\n",
      "Epoch 361/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7529 - iou_score: 0.4851 - f1-score: 0.5687 - val_loss: 0.7804 - val_iou_score: 0.4325 - val_f1-score: 0.4923\n",
      "Epoch 362/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7483 - iou_score: 0.4944 - f1-score: 0.5821 - val_loss: 0.7809 - val_iou_score: 0.4324 - val_f1-score: 0.4919\n",
      "Epoch 363/500\n",
      "12/12 [==============================] - 8s 709ms/step - loss: 0.7461 - iou_score: 0.5002 - f1-score: 0.5911 - val_loss: 0.7801 - val_iou_score: 0.4331 - val_f1-score: 0.4880\n",
      "Epoch 364/500\n",
      "12/12 [==============================] - 8s 709ms/step - loss: 0.7486 - iou_score: 0.4943 - f1-score: 0.5815 - val_loss: 0.7795 - val_iou_score: 0.4333 - val_f1-score: 0.4874\n",
      "Epoch 365/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7459 - iou_score: 0.5004 - f1-score: 0.5915 - val_loss: 0.7804 - val_iou_score: 0.4323 - val_f1-score: 0.4912\n",
      "Epoch 366/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7497 - iou_score: 0.4915 - f1-score: 0.5777 - val_loss: 0.7798 - val_iou_score: 0.4331 - val_f1-score: 0.4890\n",
      "Epoch 367/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7532 - iou_score: 0.4834 - f1-score: 0.5664 - val_loss: 0.7802 - val_iou_score: 0.4330 - val_f1-score: 0.4900\n",
      "Epoch 368/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7509 - iou_score: 0.4892 - f1-score: 0.5753 - val_loss: 0.7816 - val_iou_score: 0.4328 - val_f1-score: 0.4912\n",
      "Epoch 369/500\n",
      "12/12 [==============================] - 8s 709ms/step - loss: 0.7466 - iou_score: 0.4991 - f1-score: 0.5899 - val_loss: 0.7812 - val_iou_score: 0.4326 - val_f1-score: 0.4898\n",
      "Epoch 370/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7466 - iou_score: 0.4986 - f1-score: 0.5890 - val_loss: 0.7807 - val_iou_score: 0.4333 - val_f1-score: 0.4872\n",
      "Epoch 371/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7445 - iou_score: 0.5033 - f1-score: 0.5956 - val_loss: 0.7809 - val_iou_score: 0.4327 - val_f1-score: 0.4916\n",
      "Epoch 372/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7462 - iou_score: 0.4990 - f1-score: 0.5893 - val_loss: 0.7831 - val_iou_score: 0.4308 - val_f1-score: 0.4957\n",
      "Epoch 373/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7486 - iou_score: 0.4941 - f1-score: 0.5826 - val_loss: 0.7813 - val_iou_score: 0.4326 - val_f1-score: 0.4903\n",
      "Epoch 374/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7493 - iou_score: 0.4927 - f1-score: 0.5806 - val_loss: 0.7814 - val_iou_score: 0.4331 - val_f1-score: 0.4902\n",
      "Epoch 375/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7507 - iou_score: 0.4889 - f1-score: 0.5738 - val_loss: 0.7803 - val_iou_score: 0.4324 - val_f1-score: 0.4912\n",
      "Epoch 376/500\n",
      "12/12 [==============================] - 8s 708ms/step - loss: 0.7499 - iou_score: 0.4920 - f1-score: 0.5795 - val_loss: 0.7822 - val_iou_score: 0.4330 - val_f1-score: 0.4891\n",
      "Epoch 377/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7467 - iou_score: 0.4973 - f1-score: 0.5858 - val_loss: 0.7828 - val_iou_score: 0.4312 - val_f1-score: 0.4930\n",
      "Epoch 378/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7474 - iou_score: 0.4961 - f1-score: 0.5852 - val_loss: 0.7814 - val_iou_score: 0.4329 - val_f1-score: 0.4891\n",
      "Epoch 379/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7466 - iou_score: 0.4987 - f1-score: 0.5881 - val_loss: 0.7820 - val_iou_score: 0.4326 - val_f1-score: 0.4917\n",
      "Epoch 380/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7475 - iou_score: 0.4968 - f1-score: 0.5858 - val_loss: 0.7809 - val_iou_score: 0.4331 - val_f1-score: 0.4875\n",
      "Epoch 381/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7471 - iou_score: 0.4971 - f1-score: 0.5858 - val_loss: 0.7822 - val_iou_score: 0.4326 - val_f1-score: 0.4888\n",
      "Epoch 382/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7464 - iou_score: 0.4988 - f1-score: 0.5886 - val_loss: 0.7820 - val_iou_score: 0.4320 - val_f1-score: 0.4894\n",
      "Epoch 383/500\n",
      "12/12 [==============================] - 8s 709ms/step - loss: 0.7464 - iou_score: 0.4993 - f1-score: 0.5899 - val_loss: 0.7823 - val_iou_score: 0.4325 - val_f1-score: 0.4913\n",
      "Epoch 384/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7465 - iou_score: 0.4996 - f1-score: 0.5903 - val_loss: 0.7831 - val_iou_score: 0.4328 - val_f1-score: 0.4908\n",
      "Epoch 385/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7430 - iou_score: 0.5064 - f1-score: 0.5998 - val_loss: 0.7831 - val_iou_score: 0.4329 - val_f1-score: 0.4900\n",
      "Epoch 386/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7444 - iou_score: 0.5034 - f1-score: 0.5956 - val_loss: 0.7815 - val_iou_score: 0.4315 - val_f1-score: 0.4935\n",
      "Epoch 387/500\n",
      "12/12 [==============================] - 8s 709ms/step - loss: 0.7461 - iou_score: 0.5001 - f1-score: 0.5916 - val_loss: 0.7823 - val_iou_score: 0.4335 - val_f1-score: 0.4886\n",
      "Epoch 388/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7449 - iou_score: 0.5022 - f1-score: 0.5946 - val_loss: 0.7817 - val_iou_score: 0.4332 - val_f1-score: 0.4890\n",
      "Epoch 389/500\n",
      "12/12 [==============================] - 8s 709ms/step - loss: 0.7475 - iou_score: 0.4968 - f1-score: 0.5868 - val_loss: 0.7839 - val_iou_score: 0.4317 - val_f1-score: 0.4923\n",
      "Epoch 390/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7456 - iou_score: 0.5012 - f1-score: 0.5931 - val_loss: 0.7822 - val_iou_score: 0.4331 - val_f1-score: 0.4880\n",
      "Epoch 391/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7464 - iou_score: 0.4990 - f1-score: 0.5890 - val_loss: 0.7842 - val_iou_score: 0.4305 - val_f1-score: 0.4943\n",
      "Epoch 392/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7458 - iou_score: 0.5002 - f1-score: 0.5915 - val_loss: 0.7822 - val_iou_score: 0.4327 - val_f1-score: 0.4883\n",
      "Epoch 393/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7503 - iou_score: 0.4909 - f1-score: 0.5785 - val_loss: 0.7835 - val_iou_score: 0.4303 - val_f1-score: 0.4957\n",
      "Epoch 394/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7450 - iou_score: 0.5027 - f1-score: 0.5948 - val_loss: 0.7827 - val_iou_score: 0.4331 - val_f1-score: 0.4893\n",
      "Epoch 395/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7461 - iou_score: 0.4995 - f1-score: 0.5895 - val_loss: 0.7825 - val_iou_score: 0.4330 - val_f1-score: 0.4898\n",
      "Epoch 396/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7437 - iou_score: 0.5046 - f1-score: 0.5980 - val_loss: 0.7860 - val_iou_score: 0.4294 - val_f1-score: 0.4972\n",
      "Epoch 397/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7464 - iou_score: 0.4984 - f1-score: 0.5879 - val_loss: 0.7822 - val_iou_score: 0.4323 - val_f1-score: 0.4903\n",
      "Epoch 398/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7436 - iou_score: 0.5052 - f1-score: 0.5995 - val_loss: 0.7838 - val_iou_score: 0.4306 - val_f1-score: 0.4948\n",
      "Epoch 399/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7432 - iou_score: 0.5066 - f1-score: 0.5999 - val_loss: 0.7820 - val_iou_score: 0.4328 - val_f1-score: 0.4880\n",
      "Epoch 400/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7481 - iou_score: 0.4945 - f1-score: 0.5818 - val_loss: 0.7834 - val_iou_score: 0.4325 - val_f1-score: 0.4901\n",
      "Epoch 401/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7444 - iou_score: 0.5036 - f1-score: 0.5966 - val_loss: 0.7830 - val_iou_score: 0.4324 - val_f1-score: 0.4905\n",
      "Epoch 402/500\n",
      "12/12 [==============================] - 8s 709ms/step - loss: 0.7441 - iou_score: 0.5050 - f1-score: 0.5984 - val_loss: 0.7843 - val_iou_score: 0.4313 - val_f1-score: 0.4939\n",
      "Epoch 403/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7420 - iou_score: 0.5083 - f1-score: 0.6024 - val_loss: 0.7848 - val_iou_score: 0.4317 - val_f1-score: 0.4919\n",
      "Epoch 404/500\n",
      "12/12 [==============================] - 8s 709ms/step - loss: 0.7455 - iou_score: 0.5014 - f1-score: 0.5945 - val_loss: 0.7840 - val_iou_score: 0.4311 - val_f1-score: 0.4939\n",
      "Epoch 405/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7421 - iou_score: 0.5091 - f1-score: 0.6047 - val_loss: 0.7838 - val_iou_score: 0.4322 - val_f1-score: 0.4909\n",
      "Epoch 406/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7421 - iou_score: 0.5081 - f1-score: 0.6023 - val_loss: 0.7831 - val_iou_score: 0.4325 - val_f1-score: 0.4901\n",
      "Epoch 407/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7436 - iou_score: 0.5058 - f1-score: 0.6007 - val_loss: 0.7838 - val_iou_score: 0.4323 - val_f1-score: 0.4885\n",
      "Epoch 408/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7421 - iou_score: 0.5087 - f1-score: 0.6029 - val_loss: 0.7822 - val_iou_score: 0.4320 - val_f1-score: 0.4917\n",
      "Epoch 409/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7381 - iou_score: 0.5176 - f1-score: 0.6166 - val_loss: 0.7850 - val_iou_score: 0.4283 - val_f1-score: 0.4964\n",
      "Epoch 410/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7419 - iou_score: 0.5093 - f1-score: 0.6040 - val_loss: 0.7836 - val_iou_score: 0.4319 - val_f1-score: 0.4933\n",
      "Epoch 411/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7412 - iou_score: 0.5103 - f1-score: 0.6057 - val_loss: 0.7837 - val_iou_score: 0.4319 - val_f1-score: 0.4928\n",
      "Epoch 412/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7445 - iou_score: 0.5035 - f1-score: 0.5962 - val_loss: 0.7846 - val_iou_score: 0.4322 - val_f1-score: 0.4899\n",
      "Epoch 413/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7441 - iou_score: 0.5037 - f1-score: 0.5968 - val_loss: 0.7849 - val_iou_score: 0.4316 - val_f1-score: 0.4930\n",
      "Epoch 414/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7412 - iou_score: 0.5113 - f1-score: 0.6079 - val_loss: 0.7845 - val_iou_score: 0.4326 - val_f1-score: 0.4905\n",
      "Epoch 415/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7420 - iou_score: 0.5087 - f1-score: 0.6027 - val_loss: 0.7856 - val_iou_score: 0.4298 - val_f1-score: 0.4955\n",
      "Epoch 416/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7417 - iou_score: 0.5106 - f1-score: 0.6076 - val_loss: 0.7855 - val_iou_score: 0.4309 - val_f1-score: 0.4933\n",
      "Epoch 417/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7406 - iou_score: 0.5125 - f1-score: 0.6088 - val_loss: 0.7860 - val_iou_score: 0.4327 - val_f1-score: 0.4875\n",
      "Epoch 418/500\n",
      "12/12 [==============================] - 8s 709ms/step - loss: 0.7440 - iou_score: 0.5034 - f1-score: 0.5944 - val_loss: 0.7850 - val_iou_score: 0.4320 - val_f1-score: 0.4922\n",
      "Epoch 419/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7442 - iou_score: 0.5038 - f1-score: 0.5963 - val_loss: 0.7867 - val_iou_score: 0.4319 - val_f1-score: 0.4926\n",
      "Epoch 420/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7414 - iou_score: 0.5108 - f1-score: 0.6066 - val_loss: 0.7854 - val_iou_score: 0.4316 - val_f1-score: 0.4922\n",
      "Epoch 421/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7410 - iou_score: 0.5111 - f1-score: 0.6068 - val_loss: 0.7849 - val_iou_score: 0.4319 - val_f1-score: 0.4934\n",
      "Epoch 422/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7416 - iou_score: 0.5100 - f1-score: 0.6053 - val_loss: 0.7853 - val_iou_score: 0.4314 - val_f1-score: 0.4922\n",
      "Epoch 423/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7396 - iou_score: 0.5151 - f1-score: 0.6127 - val_loss: 0.7868 - val_iou_score: 0.4315 - val_f1-score: 0.4939\n",
      "Epoch 424/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7437 - iou_score: 0.5051 - f1-score: 0.5982 - val_loss: 0.7875 - val_iou_score: 0.4300 - val_f1-score: 0.4958\n",
      "Epoch 425/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7396 - iou_score: 0.5140 - f1-score: 0.6104 - val_loss: 0.7868 - val_iou_score: 0.4294 - val_f1-score: 0.4969\n",
      "Epoch 426/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7394 - iou_score: 0.5149 - f1-score: 0.6117 - val_loss: 0.7861 - val_iou_score: 0.4324 - val_f1-score: 0.4906\n",
      "Epoch 427/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7391 - iou_score: 0.5146 - f1-score: 0.6120 - val_loss: 0.7844 - val_iou_score: 0.4321 - val_f1-score: 0.4911\n",
      "Epoch 428/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7380 - iou_score: 0.5172 - f1-score: 0.6152 - val_loss: 0.7861 - val_iou_score: 0.4326 - val_f1-score: 0.4890\n",
      "Epoch 429/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7417 - iou_score: 0.5105 - f1-score: 0.6067 - val_loss: 0.7862 - val_iou_score: 0.4312 - val_f1-score: 0.4932\n",
      "Epoch 430/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7421 - iou_score: 0.5084 - f1-score: 0.6033 - val_loss: 0.7850 - val_iou_score: 0.4319 - val_f1-score: 0.4912\n",
      "Epoch 431/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7449 - iou_score: 0.5033 - f1-score: 0.5964 - val_loss: 0.7864 - val_iou_score: 0.4302 - val_f1-score: 0.4945\n",
      "Epoch 432/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7423 - iou_score: 0.5080 - f1-score: 0.6027 - val_loss: 0.7863 - val_iou_score: 0.4322 - val_f1-score: 0.4905\n",
      "Epoch 433/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7428 - iou_score: 0.5094 - f1-score: 0.6058 - val_loss: 0.7881 - val_iou_score: 0.4307 - val_f1-score: 0.4952\n",
      "Epoch 434/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7380 - iou_score: 0.5179 - f1-score: 0.6159 - val_loss: 0.7864 - val_iou_score: 0.4318 - val_f1-score: 0.4929\n",
      "Epoch 435/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7373 - iou_score: 0.5202 - f1-score: 0.6190 - val_loss: 0.7887 - val_iou_score: 0.4299 - val_f1-score: 0.4963\n",
      "Epoch 436/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7395 - iou_score: 0.5146 - f1-score: 0.6113 - val_loss: 0.7875 - val_iou_score: 0.4305 - val_f1-score: 0.4940\n",
      "Epoch 437/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7386 - iou_score: 0.5165 - f1-score: 0.6147 - val_loss: 0.7875 - val_iou_score: 0.4319 - val_f1-score: 0.4914\n",
      "Epoch 438/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7370 - iou_score: 0.5195 - f1-score: 0.6175 - val_loss: 0.7873 - val_iou_score: 0.4312 - val_f1-score: 0.4937\n",
      "Epoch 439/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7380 - iou_score: 0.5176 - f1-score: 0.6160 - val_loss: 0.7940 - val_iou_score: 0.4243 - val_f1-score: 0.5002\n",
      "Epoch 440/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7414 - iou_score: 0.5099 - f1-score: 0.6046 - val_loss: 0.7873 - val_iou_score: 0.4318 - val_f1-score: 0.4917\n",
      "Epoch 441/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7405 - iou_score: 0.5129 - f1-score: 0.6107 - val_loss: 0.7876 - val_iou_score: 0.4301 - val_f1-score: 0.4956\n",
      "Epoch 442/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7410 - iou_score: 0.5108 - f1-score: 0.6059 - val_loss: 0.7880 - val_iou_score: 0.4322 - val_f1-score: 0.4910\n",
      "Epoch 443/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7374 - iou_score: 0.5192 - f1-score: 0.6175 - val_loss: 0.7894 - val_iou_score: 0.4296 - val_f1-score: 0.4965\n",
      "Epoch 444/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7332 - iou_score: 0.5273 - f1-score: 0.6285 - val_loss: 0.7889 - val_iou_score: 0.4313 - val_f1-score: 0.4934\n",
      "Epoch 445/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7382 - iou_score: 0.5170 - f1-score: 0.6157 - val_loss: 0.7895 - val_iou_score: 0.4300 - val_f1-score: 0.4953\n",
      "Epoch 446/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7391 - iou_score: 0.5155 - f1-score: 0.6132 - val_loss: 0.7886 - val_iou_score: 0.4318 - val_f1-score: 0.4927\n",
      "Epoch 447/500\n",
      "12/12 [==============================] - 8s 709ms/step - loss: 0.7348 - iou_score: 0.5251 - f1-score: 0.6256 - val_loss: 0.7886 - val_iou_score: 0.4307 - val_f1-score: 0.4945\n",
      "Epoch 448/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7351 - iou_score: 0.5236 - f1-score: 0.6243 - val_loss: 0.7891 - val_iou_score: 0.4304 - val_f1-score: 0.4953\n",
      "Epoch 449/500\n",
      "12/12 [==============================] - 8s 714ms/step - loss: 0.7371 - iou_score: 0.5203 - f1-score: 0.6198 - val_loss: 0.7886 - val_iou_score: 0.4319 - val_f1-score: 0.4902\n",
      "Epoch 450/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7371 - iou_score: 0.5190 - f1-score: 0.6182 - val_loss: 0.7892 - val_iou_score: 0.4321 - val_f1-score: 0.4910\n",
      "Epoch 451/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7360 - iou_score: 0.5217 - f1-score: 0.6211 - val_loss: 0.7900 - val_iou_score: 0.4318 - val_f1-score: 0.4925\n",
      "Epoch 452/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7339 - iou_score: 0.5265 - f1-score: 0.6279 - val_loss: 0.7893 - val_iou_score: 0.4311 - val_f1-score: 0.4937\n",
      "Epoch 453/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7335 - iou_score: 0.5283 - f1-score: 0.6304 - val_loss: 0.7902 - val_iou_score: 0.4311 - val_f1-score: 0.4943\n",
      "Epoch 454/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7383 - iou_score: 0.5174 - f1-score: 0.6149 - val_loss: 0.7896 - val_iou_score: 0.4317 - val_f1-score: 0.4925\n",
      "Epoch 455/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7397 - iou_score: 0.5136 - f1-score: 0.6109 - val_loss: 0.7907 - val_iou_score: 0.4318 - val_f1-score: 0.4913\n",
      "Epoch 456/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7355 - iou_score: 0.5229 - f1-score: 0.6231 - val_loss: 0.7893 - val_iou_score: 0.4292 - val_f1-score: 0.4969\n",
      "Epoch 457/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7378 - iou_score: 0.5175 - f1-score: 0.6162 - val_loss: 0.7902 - val_iou_score: 0.4313 - val_f1-score: 0.4918\n",
      "Epoch 458/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7332 - iou_score: 0.5275 - f1-score: 0.6283 - val_loss: 0.7899 - val_iou_score: 0.4321 - val_f1-score: 0.4910\n",
      "Epoch 459/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7371 - iou_score: 0.5214 - f1-score: 0.6218 - val_loss: 0.7904 - val_iou_score: 0.4315 - val_f1-score: 0.4920\n",
      "Epoch 460/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7345 - iou_score: 0.5256 - f1-score: 0.6272 - val_loss: 0.7908 - val_iou_score: 0.4305 - val_f1-score: 0.4945\n",
      "Epoch 461/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7352 - iou_score: 0.5230 - f1-score: 0.6230 - val_loss: 0.7897 - val_iou_score: 0.4292 - val_f1-score: 0.4963\n",
      "Epoch 462/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7400 - iou_score: 0.5136 - f1-score: 0.6108 - val_loss: 0.7922 - val_iou_score: 0.4289 - val_f1-score: 0.4972\n",
      "Epoch 463/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7341 - iou_score: 0.5255 - f1-score: 0.6267 - val_loss: 0.7903 - val_iou_score: 0.4301 - val_f1-score: 0.4948\n",
      "Epoch 464/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7317 - iou_score: 0.5313 - f1-score: 0.6346 - val_loss: 0.7912 - val_iou_score: 0.4307 - val_f1-score: 0.4950\n",
      "Epoch 465/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7375 - iou_score: 0.5194 - f1-score: 0.6182 - val_loss: 0.7906 - val_iou_score: 0.4299 - val_f1-score: 0.4957\n",
      "Epoch 466/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7298 - iou_score: 0.5354 - f1-score: 0.6394 - val_loss: 0.7913 - val_iou_score: 0.4302 - val_f1-score: 0.4951\n",
      "Epoch 467/500\n",
      "12/12 [==============================] - 8s 712ms/step - loss: 0.7269 - iou_score: 0.5409 - f1-score: 0.6456 - val_loss: 0.7915 - val_iou_score: 0.4304 - val_f1-score: 0.4953\n",
      "Epoch 468/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7304 - iou_score: 0.5339 - f1-score: 0.6371 - val_loss: 0.7900 - val_iou_score: 0.4310 - val_f1-score: 0.4930\n",
      "Epoch 469/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7336 - iou_score: 0.5260 - f1-score: 0.6276 - val_loss: 0.7915 - val_iou_score: 0.4309 - val_f1-score: 0.4937\n",
      "Epoch 470/500\n",
      "12/12 [==============================] - 8s 709ms/step - loss: 0.7344 - iou_score: 0.5251 - f1-score: 0.6264 - val_loss: 0.7910 - val_iou_score: 0.4295 - val_f1-score: 0.4956\n",
      "Epoch 471/500\n",
      "12/12 [==============================] - 8s 710ms/step - loss: 0.7337 - iou_score: 0.5264 - f1-score: 0.6270 - val_loss: 0.7944 - val_iou_score: 0.4304 - val_f1-score: 0.4944\n",
      "Epoch 472/500\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 0.7322 - iou_score: 0.5296 - f1-score: 0.6312 - val_loss: 0.7912 - val_iou_score: 0.4297 - val_f1-score: 0.4951\n",
      "Epoch 473/500\n",
      "12/12 [==============================] - 8s 709ms/step - loss: 0.7310 - iou_score: 0.5329 - f1-score: 0.6368 - val_loss: 0.7923 - val_iou_score: 0.4294 - val_f1-score: 0.4955\n",
      "Epoch 474/500\n",
      "12/12 [==============================] - 8s 713ms/step - loss: 0.7285 - iou_score: 0.5374 - f1-score: 0.6414 - val_loss: 0.7921 - val_iou_score: 0.4312 - val_f1-score: 0.4929\n",
      "Epoch 475/500\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 0.7300 - iou_score: 0.5344 - f1-score: 0.6384"
     ]
    }
   ],
   "source": [
    "# train \n",
    "\n",
    "history=model.fit(X_train_prep, \n",
    "          Y_train,\n",
    "          batch_size=8, \n",
    "          epochs=TRAIN,\n",
    "          verbose=1,\n",
    "          validation_data=(X_val_prep, Y_val),\n",
    "         callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "\n",
    "model.save('./3DUnet/model/3D_model_vgg16_500epochs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the loss and IOU loss\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "acc = history.history['iou_score']\n",
    "val_acc = history.history['val_iou_score']\n",
    "\n",
    "plt.plot(epochs, acc, 'y', label='Training IOU')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation IOU')\n",
    "plt.title('Training and validation IOU')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('IOU')\n",
    "plt.legend()\n",
    "plt.show() # Save model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "\n",
    "from keras.models import load_model\n",
    "# from keras.models import load_model\n",
    "my_model = load_model('./3DUnet/model/3D_model_vgg16_500epochs.h5', compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the test data\n",
    "\n",
    "X_test_prep = preprocess_input(X_test) \n",
    "\n",
    "print('before pre:', np.min(X_test), np.max(X_test))\n",
    "print('after pre:', np.min(X_test_prep), np.max(X_test_prep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on the test set\n",
    "\n",
    "Y_pred = my_model.predict(X_test_prep)\n",
    "\n",
    "Y_pred = np.asarray(Y_pred)\n",
    "Y_pred_argmax = np.argmax(Y_pred, axis=4) \n",
    "Y_test_argmax = np.argmax(Y_test, axis=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check for the data shape\n",
    "\n",
    "print(Y_pred_argmax.shape)\n",
    "print(Y_test_argmax.shape)\n",
    "print(np.unique(Y_pred_argmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test in rando\n",
    "import random\n",
    "test_img_number = random.randint(0, len(X_test))\n",
    "test_img = X_test[test_img_number]\n",
    "ground_truth = Y_test[test_img_number]\n",
    "ground_truth = np.squeeze(ground_truth)\n",
    "\n",
    "test_img_input=np.expand_dims(test_img, 0)\n",
    "test_img_input1 = preprocess_input(test_img_input)\n",
    "\n",
    "test_pred1 = my_model.predict(test_img_input1)\n",
    "test_prediction1 = np.argmax(test_pred1, axis=4)[0,:,:,:]\n",
    "print('pred size:', test_prediction1.shape,' GT size:', ground_truth.shape, 'input size:', test_img.shape )\n",
    "print(test_img.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_img[0,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check for the data matching\n",
    "\n",
    "sliceNum = 10\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(test_img[sliceNum,...]/255, cmap='gray')  # input\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(ground_truth[sliceNum,...], cmap='gray')  # GT\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(test_prediction1[sliceNum,...], cmap='gray') # pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpatchify back into the cubes\n",
    "\n",
    "imagePatch = np.reshape(np.asarray(Y_pred_argmax),\n",
    "                (unpatchParaTest[0], unpatchParaTest[1],unpatchParaTest[2],\n",
    "                 unpatchParaTest[3], unpatchParaTest[4],unpatchParaTest[5]))\n",
    "origTest = unpatchify(imagePatch, testStackSize)\n",
    "print(origTest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting out the input, GT and prediction\n",
    "\n",
    "# Y_test_raw needs to be binarized, then it can matched with prediction\n",
    "Y_test_raw_bi = ((Y_test_raw/ 255) > 0.5).astype(np.float)\n",
    "\n",
    "for i in range(origTest.shape[0]):\n",
    "    \n",
    "    predT = origTest[i,...] \n",
    "    focalT = X_test_raw[i,...] / 255\n",
    "    truthT = Y_test_raw_bi[i,...] \n",
    "\n",
    "    bar = np.ones((predT.shape[0], 15))   # lines\n",
    "    combTemp = np.concatenate((focalT, bar, predT, bar, truthT), axis=1)\n",
    "\n",
    "    if DOCUMENT:\n",
    "        # upload the test results into neptune with handle 'description'\n",
    "        run[\"test/sample_images\"].log(neptune.types.File.as_image(combTemp), name=str(i), description='test images from 3rd stack')  \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop the neptune\n",
    "if DOCUMENT:\n",
    "    run.stop() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the generated results locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check for the results\n",
    "\n",
    "tempIMG = origTest[0,:,:]\n",
    "\n",
    "plt.imshow(tempIMG, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the three dataset together\n",
    "\n",
    "NUM = 100\n",
    "predT = origTest[NUM,...] #* 255\n",
    "plt.figure()\n",
    "plt.imshow(predT, cmap='gray')\n",
    "focalT = X_test_raw[NUM,...]/255\n",
    "truthT = Y_test_raw_bi[NUM,...] #* 255\n",
    "\n",
    "bar = np.ones((predT.shape[0], 15)) #* 255  # lines\n",
    "combTemp = np.concatenate((focalT, bar, predT, bar, truthT), axis=1)\n",
    "plt.imshow(combTemp, cmap='gray')\n",
    "\n",
    "\n",
    "# print(X_test_raw.shape, Y_test_raw_bi.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install \"napari[all]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# veiw the 3D volume \n",
    "# not working on the hemera\n",
    "\n",
    "# from skimage import data\n",
    "# import napari\n",
    "\n",
    "# viewer = napari.view_image(data.cells3d(), channel_axis=1, ndisplay=3)\n",
    "\n",
    "# viewer = napari.view_image(original, channel_axis=1, ndisplay=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CONDA (seg)",
   "language": "python",
   "name": "seg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
